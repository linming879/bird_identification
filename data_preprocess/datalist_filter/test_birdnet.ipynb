{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = 'E:/AMR/DA/Projekt/data/data_list/0408'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "import numpy as np\n",
    "\n",
    "# === 配置路径 ===\n",
    "AUDIO_PATH = \"E:/AMR/DA/Projekt/data/Audio_files/Call - Great Tit/XC924149.wav\"\n",
    "OUTPUT_CSV = \"E:/AMR/DA/Projekt/bird_cls_cnn/data_preprocess/test_demo/birdnet_prediction_result.csv\"\n",
    "OUTPUT_SPEC = \"E:/AMR/DA/Projekt/bird_cls_cnn/data_preprocess/test_demo/spec_folder\"\n",
    "os.makedirs(OUTPUT_SPEC, exist_ok=True)\n",
    "\n",
    "# 提取编号（如 XC638874 或 negative_001）\n",
    "XC_NUMBER = os.path.splitext(os.path.basename(AUDIO_PATH))[0]\n",
    "\n",
    "# BirdNET 推理器\n",
    "analyzer = Analyzer()\n",
    "rec = Recording(analyzer, AUDIO_PATH)\n",
    "rec.analyze()\n",
    "\n",
    "# === 提取推理结果 ===\n",
    "results = []\n",
    "for detection in rec.detections:\n",
    "    start_time = detection[\"start_time\"]\n",
    "    seg_idx = int(start_time // 3)\n",
    "\n",
    "    results.append({\n",
    "        \"number\": XC_NUMBER,\n",
    "        \"segment_index\": seg_idx,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": detection[\"end_time\"],\n",
    "        \"common_name\": detection[\"common_name\"],\n",
    "        \"confidence\": detection[\"confidence\"]\n",
    "    })\n",
    "\n",
    "# 转为 DataFrame，按 seg 保留最高置信度预测\n",
    "df = pd.DataFrame(results)\n",
    "df_top1 = (\n",
    "    df.sort_values(\"confidence\", ascending=False)\n",
    "      .groupby([\"number\", \"segment_index\"])\n",
    "      .head(1)\n",
    "      .reset_index(drop=True)\n",
    "      .sort_values(\"segment_index\")\n",
    ")\n",
    "\n",
    "# === 加载音频用于频谱图生成 ===\n",
    "y, sr = librosa.load(AUDIO_PATH, sr=48000)\n",
    "\n",
    "# === 遍历每个保留的 segment，生成频谱图 ===\n",
    "for _, row in df_top1.iterrows():\n",
    "    seg_idx = int(row[\"segment_index\"])\n",
    "    start_sample = seg_idx * 3 * sr\n",
    "    end_sample = (seg_idx + 1) * 3 * sr\n",
    "    segment_audio = y[int(start_sample):int(end_sample)]\n",
    "\n",
    "    # 生成 STFT 幅度谱图\n",
    "    D = librosa.stft(segment_audio, n_fft=512, hop_length=256)\n",
    "    S_db = librosa.amplitude_to_db(abs(D), ref=np.max)\n",
    "\n",
    "    # 画图并保存\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    librosa.display.specshow(S_db, sr=sr, hop_length=256, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Spec: {XC_NUMBER} seg {seg_idx}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(OUTPUT_SPEC, f\"{XC_NUMBER}_seg{seg_idx}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# === 保存推理结果 CSV ===\n",
    "df_top1.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ 推理完成，预测结果保存至: {OUTPUT_CSV}\")\n",
    "print(f\"🖼️ 每段频谱图已保存至: {OUTPUT_SPEC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird net批跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "\n",
    "# === 配置路径 ===\n",
    "CSV_PATH = f\"{root_data_path}/train_meta_100_deduplicated.csv\"  # 包含 path 列的 CSV\n",
    "OUTPUT_CSV_SORTED = f\"{root_data_path}/birdnet_all_predictions_sorted.csv\"\n",
    "\n",
    "# 初始化 BirdNET Analyzer\n",
    "analyzer = Analyzer()\n",
    "\n",
    "# 读取 CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 存储所有结果\n",
    "all_results = []\n",
    "\n",
    "# 遍历每个唯一音频（按 number 分组）\n",
    "for number in df[\"number\"].unique():\n",
    "    row = df[df[\"number\"] == number].iloc[0]\n",
    "    file_path = row[\"path\"]\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ 音频文件不存在: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 推理\n",
    "        rec = Recording(analyzer, file_path)\n",
    "        rec.analyze()\n",
    "\n",
    "        # 提取预测结果\n",
    "        detections = rec.detections\n",
    "        if len(detections) == 0:\n",
    "            continue\n",
    "\n",
    "        # 构建结果\n",
    "        results = []\n",
    "        for d in detections:\n",
    "            seg_idx = int(d[\"start_time\"] // 3)\n",
    "            results.append({\n",
    "                \"number\": number,\n",
    "                \"segment_index\": seg_idx,\n",
    "                \"start_time\": d[\"start_time\"],\n",
    "                \"end_time\": d[\"end_time\"],\n",
    "                \"common_name\": d[\"common_name\"],\n",
    "                \"confidence\": d[\"confidence\"]\n",
    "            })\n",
    "\n",
    "        # 每段保留置信度最高的预测\n",
    "        df_pred = pd.DataFrame(results)\n",
    "        df_top1 = (\n",
    "            df_pred.sort_values(\"confidence\", ascending=False)\n",
    "                   .groupby([\"number\", \"segment_index\"])\n",
    "                   .head(1)\n",
    "                   .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        all_results.append(df_top1)\n",
    "        print(f\"✅ 完成推理: {number}, 有效片段数: {len(df_top1)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 推理失败: {file_path}, 错误: {e}\")\n",
    "\n",
    "# 合并结果并排序保存\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    final_df = final_df.sort_values(by=[\"number\", \"segment_index\"]).reset_index(drop=True)\n",
    "    final_df.to_csv(OUTPUT_CSV_SORTED, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n✅ 推理和排序完成，最终结果保存至: {OUTPUT_CSV_SORTED}\")\n",
    "else:\n",
    "    print(\"⚠️ 无有效推理结果生成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 修正后的 train list 已保存至: E:/AMR/DA/Projekt/data/data_list/0408/all_data_meta_allTypes_high_quality.csv\n",
      "🎯 保留样本数: 102147 / 原始样本数: 186980\n",
      "❌ 舍弃样本数（预测缺失 & 不一致）: 84833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 配置路径 ===\n",
    "TRAIN_CSV = f\"{root_data_path}/all_data_meta_allTypes.csv\"\n",
    "BIRDNET_CSV = f\"{root_data_path}/birdnet_all_predictions_sorted.csv\"\n",
    "OUTPUT_CSV = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "\n",
    "# === 加载数据 ===\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "birdnet_df = pd.read_csv(BIRDNET_CSV)\n",
    "\n",
    "# === ✅ 替换名称：将 \"Common Blackbird\" 统一改为 \"Eurasian Blackbird\"\n",
    "train_df[\"bird_name\"] = train_df[\"bird_name\"].replace(\"Common Blackbird\", \"Eurasian Blackbird\")\n",
    "\n",
    "# === 统一小写以便对比\n",
    "train_df[\"bird_name_lower\"] = train_df[\"bird_name\"].str.lower()\n",
    "birdnet_df[\"common_name_lower\"] = birdnet_df[\"common_name\"].str.lower()\n",
    "\n",
    "# === 合并两个表格（按 number 和 segment_index 匹配）\n",
    "merged = train_df.merge(\n",
    "    birdnet_df,\n",
    "    how=\"left\",\n",
    "    on=[\"number\", \"segment_index\"]\n",
    ")\n",
    "\n",
    "# === 条件 1：BirdNET 有结果 且 label 一致\n",
    "condition1 = (merged[\"common_name_lower\"].notna()) & (merged[\"bird_name_lower\"] == merged[\"common_name_lower\"])\n",
    "\n",
    "# === 条件 2：标注为 Background Noise（直接保留）\n",
    "condition2 = (merged[\"bird_name\"] == \"Background Noise\")\n",
    "\n",
    "# === 满足任一条件即可保留\n",
    "cleaned_df = merged[condition1 | condition2]\n",
    "\n",
    "# === 导出原始字段\n",
    "cleaned_train_df = cleaned_df[train_df.columns]\n",
    "cleaned_train_df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# === 输出信息\n",
    "print(f\"✅ 修正后的 train list 已保存至: {OUTPUT_CSV}\")\n",
    "print(f\"🎯 保留样本数: {len(cleaned_train_df)} / 原始样本数: {len(train_df)}\")\n",
    "print(f\"❌ 舍弃样本数（预测缺失 & 不一致）: {len(train_df) - len(cleaned_train_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比新旧标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 类别总数（旧数据）: 33\n",
      "📊 类别总数（新数据）: 33\n",
      "\n",
      "✅ 所有类别均有保留\n",
      "\n",
      "📊 类别数量对比：\n",
      "                          Old Count  New Count\n",
      "bird_name                                     \n",
      "Background Noise               3000       3000\n",
      "Black-headed Gull              4398       2800\n",
      "Canada Goose                   4924       3065\n",
      "Carrion Crow                   5400       1893\n",
      "Common Chaffinch               7961       3375\n",
      "Common Kingfisher              3117       1808\n",
      "Common Redstart                4921       2280\n",
      "Dunnock                        4307       2854\n",
      "Eurasian Blackbird             8219       4459\n",
      "Eurasian Blackcap             10771       4726\n",
      "Eurasian Blue Tit              5793       3285\n",
      "Eurasian Bullfinch             4818       3035\n",
      "Eurasian Coot                  4512       2576\n",
      "Eurasian Golden Oriole         5066       2980\n",
      "Eurasian Jay                   9214       2988\n",
      "Eurasian Nuthatch              5203       3058\n",
      "Eurasian Siskin                5495       4145\n",
      "Eurasian Treecreeper           4995       2399\n",
      "Eurasian Wren                  8137       4158\n",
      "European Goldfinch             4387       3320\n",
      "European Robin                 8929       4616\n",
      "Goldcrest                      4650       2713\n",
      "Great Spotted Woodpecker       4103       2769\n",
      "Great Tit                      6921       2659\n",
      "Hawfinch                       4135       2969\n",
      "Hooded Crow                    8236       2342\n",
      "Long-tailed Tit                7175       5138\n",
      "Mallard                        4034       2371\n",
      "Marsh Tit                      4690       2801\n",
      "Redwing                        4850       3518\n",
      "Rook                           4143       3267\n",
      "Short-toed Treecreeper         5186       3020\n",
      "Stock Dove                     5290       1760\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 配置路径 ===\n",
    "old_csv_path = f\"{root_data_path}/all_data_meta_allTypes.csv\"\n",
    "new_csv_path = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "\n",
    "# === 读取 CSV 文件 ===\n",
    "df_old = pd.read_csv(old_csv_path)\n",
    "df_new = pd.read_csv(new_csv_path)\n",
    "\n",
    "# === ✅ 替换类别名称：Common Blackbird → Eurasian Blackbird\n",
    "df_old[\"bird_name\"] = df_old[\"bird_name\"].replace(\"Common Blackbird\", \"Eurasian Blackbird\")\n",
    "\n",
    "# === 获取类别分布 ===\n",
    "old_counts = df_old[\"bird_name\"].value_counts().sort_index()\n",
    "new_counts = df_new[\"bird_name\"].value_counts().sort_index()\n",
    "\n",
    "# === 合并对比表 ===\n",
    "compare_df = pd.DataFrame({\n",
    "    \"Old Count\": old_counts,\n",
    "    \"New Count\": new_counts\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# === 打印类别总数信息 ===\n",
    "num_classes_old = compare_df[\"Old Count\"].astype(bool).sum()\n",
    "num_classes_new = compare_df[\"New Count\"].astype(bool).sum()\n",
    "\n",
    "print(f\"\\n📊 类别总数（旧数据）: {num_classes_old}\")\n",
    "print(f\"📊 类别总数（新数据）: {num_classes_new}\")\n",
    "\n",
    "# === 打印缺失类别（在新数据中为0的）\n",
    "missing_classes = compare_df[compare_df[\"New Count\"] == 0]\n",
    "if not missing_classes.empty:\n",
    "    print(f\"\\n❌ 以下 {len(missing_classes)} 个类别在精修后被完全剔除：\")\n",
    "    print(missing_classes)\n",
    "else:\n",
    "    print(\"\\n✅ 所有类别均有保留\")\n",
    "\n",
    "# === 打印类别数量对比表 ===\n",
    "print(\"\\n📊 类别数量对比：\")\n",
    "print(compare_df)\n",
    "\n",
    "# # === 保存对比表 ===\n",
    "# output_path = \"E:/AMR/DA/Projekt/data/data_list/0401/class_distribution_comparison_fixed.csv\"\n",
    "# compare_df.to_csv(output_path, encoding=\"utf-8-sig\")\n",
    "# print(f\"\\n✅ 分布对比表已保存至: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 训练集保存至: E:/AMR/DA/Projekt/data/data_list/0408/train_list_high_quality.csv，共 92247 条\n",
      "✅ 测试集保存至: E:/AMR/DA/Projekt/data/data_list/0408/valid_list_high_quality.csv，共 9900 条\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 配置路径 ===\n",
    "INPUT_CSV = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "TRAIN_CSV = f\"{root_data_path}/train_list_high_quality.csv\"\n",
    "TEST_CSV = f\"{root_data_path}/valid_list_high_quality.csv\"\n",
    "Valid_Num = 300\n",
    "\n",
    "# === 读取数据 ===\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# ✅ 分出 Background Noise 与其他类别\n",
    "is_bg = df[\"bird_name\"] == \"Background Noise\"\n",
    "bg_df = df[is_bg & df[\"segment_index\"].isin([0, 1, 2])].copy()\n",
    "non_bg_df = df[~is_bg].copy()\n",
    "\n",
    "# === 初始化容器\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# ✅ 处理非 Background Noise 类别\n",
    "for bird in non_bg_df[\"bird_name\"].unique():\n",
    "    class_df = non_bg_df[non_bg_df[\"bird_name\"] == bird]\n",
    "    grouped = class_df.groupby(\"number\")\n",
    "    groups = list(grouped.groups.items())\n",
    "\n",
    "    test_samples = []\n",
    "    used_numbers = set()\n",
    "    total_test_segments = 0\n",
    "    target_segments = Valid_Num\n",
    "\n",
    "    for number, indices in groups:\n",
    "        group_samples = class_df.loc[indices]\n",
    "        group_len = len(group_samples)\n",
    "\n",
    "        # 精确控制测试集大小\n",
    "        if group_len <= (target_segments - total_test_segments):\n",
    "            test_samples.append(group_samples)\n",
    "            used_numbers.add(number)\n",
    "            total_test_segments += group_len\n",
    "        if total_test_segments >= target_segments:\n",
    "            break\n",
    "\n",
    "    if test_samples:\n",
    "        test_df = pd.concat(test_samples)\n",
    "        test_list.append(test_df)\n",
    "        train_df = class_df[~class_df[\"number\"].isin(used_numbers)]\n",
    "        train_list.append(train_df)\n",
    "\n",
    "# ✅ 精准划分 Background Noise（seg0~2）\n",
    "bg_grouped = bg_df.groupby(\"number\")\n",
    "bg_test, bg_train = [], []\n",
    "total_bg_test = 0\n",
    "target_bg_test = Valid_Num\n",
    "\n",
    "for number, group in bg_grouped:\n",
    "    group = group[group[\"segment_index\"].isin([0, 1, 2])]\n",
    "    group_len = len(group)\n",
    "\n",
    "    if total_bg_test + group_len <= target_bg_test:\n",
    "        bg_test.append(group)\n",
    "        total_bg_test += group_len\n",
    "    else:\n",
    "        bg_train.append(group)\n",
    "\n",
    "# === 合并训练和测试集\n",
    "final_train = pd.concat(train_list + bg_train).reset_index(drop=True)\n",
    "final_test = pd.concat(test_list + bg_test).reset_index(drop=True)\n",
    "\n",
    "# === 保存结果\n",
    "final_train.to_csv(TRAIN_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "final_test.to_csv(TEST_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 训练集保存至: {TRAIN_CSV}，共 {len(final_train)} 条\")\n",
    "print(f\"✅ 测试集保存至: {TEST_CSV}，共 {len(final_test)} 条\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 两个列表中的鸟类完全不重复！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === 配置路径 ===\n",
    "CSV_1_PATH = f\"{root_data_path}/train_list_high_quality.csv\"\n",
    "CSV_2_PATH = f\"{root_data_path}/valid_list_high_quality.csv\"\n",
    "\n",
    "# === 读取 CSV ===\n",
    "df1 = pd.read_csv(CSV_1_PATH)\n",
    "df2 = pd.read_csv(CSV_2_PATH)\n",
    "\n",
    "# === 提取 bird_name 集合\n",
    "birds_1 = set(df1[\"number\"].unique())\n",
    "birds_2 = set(df2[\"number\"].unique())\n",
    "\n",
    "# === 查找交集\n",
    "common_birds = birds_1.intersection(birds_2)\n",
    "\n",
    "# === 打印结果\n",
    "if common_birds:\n",
    "    print(f\"⚠️ 两个 CSV 存在 {len(common_birds)} 个重复的鸟类：\")\n",
    "    for bird in sorted(common_birds):\n",
    "        print(\" -\", bird)\n",
    "else:\n",
    "    print(\"✅ 两个列表中的鸟类完全不重复！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
