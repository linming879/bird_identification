{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = 'E:/AMR/DA/Projekt/data/data_list/0408'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "import numpy as np\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "AUDIO_PATH = \"E:/AMR/DA/Projekt/data/Audio_files/Call - Great Tit/XC924149.wav\"\n",
    "OUTPUT_CSV = \"E:/AMR/DA/Projekt/bird_cls_cnn/data_preprocess/test_demo/birdnet_prediction_result.csv\"\n",
    "OUTPUT_SPEC = \"E:/AMR/DA/Projekt/bird_cls_cnn/data_preprocess/test_demo/spec_folder\"\n",
    "os.makedirs(OUTPUT_SPEC, exist_ok=True)\n",
    "\n",
    "# æå–ç¼–å·ï¼ˆå¦‚ XC638874 æˆ– negative_001ï¼‰\n",
    "XC_NUMBER = os.path.splitext(os.path.basename(AUDIO_PATH))[0]\n",
    "\n",
    "# BirdNET æ¨ç†å™¨\n",
    "analyzer = Analyzer()\n",
    "rec = Recording(analyzer, AUDIO_PATH)\n",
    "rec.analyze()\n",
    "\n",
    "# === æå–æ¨ç†ç»“æœ ===\n",
    "results = []\n",
    "for detection in rec.detections:\n",
    "    start_time = detection[\"start_time\"]\n",
    "    seg_idx = int(start_time // 3)\n",
    "\n",
    "    results.append({\n",
    "        \"number\": XC_NUMBER,\n",
    "        \"segment_index\": seg_idx,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": detection[\"end_time\"],\n",
    "        \"common_name\": detection[\"common_name\"],\n",
    "        \"confidence\": detection[\"confidence\"]\n",
    "    })\n",
    "\n",
    "# è½¬ä¸º DataFrameï¼ŒæŒ‰ seg ä¿ç•™æœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹\n",
    "df = pd.DataFrame(results)\n",
    "df_top1 = (\n",
    "    df.sort_values(\"confidence\", ascending=False)\n",
    "      .groupby([\"number\", \"segment_index\"])\n",
    "      .head(1)\n",
    "      .reset_index(drop=True)\n",
    "      .sort_values(\"segment_index\")\n",
    ")\n",
    "\n",
    "# === åŠ è½½éŸ³é¢‘ç”¨äºé¢‘è°±å›¾ç”Ÿæˆ ===\n",
    "y, sr = librosa.load(AUDIO_PATH, sr=48000)\n",
    "\n",
    "# === éå†æ¯ä¸ªä¿ç•™çš„ segmentï¼Œç”Ÿæˆé¢‘è°±å›¾ ===\n",
    "for _, row in df_top1.iterrows():\n",
    "    seg_idx = int(row[\"segment_index\"])\n",
    "    start_sample = seg_idx * 3 * sr\n",
    "    end_sample = (seg_idx + 1) * 3 * sr\n",
    "    segment_audio = y[int(start_sample):int(end_sample)]\n",
    "\n",
    "    # ç”Ÿæˆ STFT å¹…åº¦è°±å›¾\n",
    "    D = librosa.stft(segment_audio, n_fft=512, hop_length=256)\n",
    "    S_db = librosa.amplitude_to_db(abs(D), ref=np.max)\n",
    "\n",
    "    # ç”»å›¾å¹¶ä¿å­˜\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    librosa.display.specshow(S_db, sr=sr, hop_length=256, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Spec: {XC_NUMBER} seg {seg_idx}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(OUTPUT_SPEC, f\"{XC_NUMBER}_seg{seg_idx}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# === ä¿å­˜æ¨ç†ç»“æœ CSV ===\n",
    "df_top1.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… æ¨ç†å®Œæˆï¼Œé¢„æµ‹ç»“æœä¿å­˜è‡³: {OUTPUT_CSV}\")\n",
    "print(f\"ğŸ–¼ï¸ æ¯æ®µé¢‘è°±å›¾å·²ä¿å­˜è‡³: {OUTPUT_SPEC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird netæ‰¹è·‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "CSV_PATH = f\"{root_data_path}/train_meta_100_deduplicated.csv\"  # åŒ…å« path åˆ—çš„ CSV\n",
    "OUTPUT_CSV_SORTED = f\"{root_data_path}/birdnet_all_predictions_sorted.csv\"\n",
    "\n",
    "# åˆå§‹åŒ– BirdNET Analyzer\n",
    "analyzer = Analyzer()\n",
    "\n",
    "# è¯»å– CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# å­˜å‚¨æ‰€æœ‰ç»“æœ\n",
    "all_results = []\n",
    "\n",
    "# éå†æ¯ä¸ªå”¯ä¸€éŸ³é¢‘ï¼ˆæŒ‰ number åˆ†ç»„ï¼‰\n",
    "for number in df[\"number\"].unique():\n",
    "    row = df[df[\"number\"] == number].iloc[0]\n",
    "    file_path = row[\"path\"]\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # æ¨ç†\n",
    "        rec = Recording(analyzer, file_path)\n",
    "        rec.analyze()\n",
    "\n",
    "        # æå–é¢„æµ‹ç»“æœ\n",
    "        detections = rec.detections\n",
    "        if len(detections) == 0:\n",
    "            continue\n",
    "\n",
    "        # æ„å»ºç»“æœ\n",
    "        results = []\n",
    "        for d in detections:\n",
    "            seg_idx = int(d[\"start_time\"] // 3)\n",
    "            results.append({\n",
    "                \"number\": number,\n",
    "                \"segment_index\": seg_idx,\n",
    "                \"start_time\": d[\"start_time\"],\n",
    "                \"end_time\": d[\"end_time\"],\n",
    "                \"common_name\": d[\"common_name\"],\n",
    "                \"confidence\": d[\"confidence\"]\n",
    "            })\n",
    "\n",
    "        # æ¯æ®µä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„é¢„æµ‹\n",
    "        df_pred = pd.DataFrame(results)\n",
    "        df_top1 = (\n",
    "            df_pred.sort_values(\"confidence\", ascending=False)\n",
    "                   .groupby([\"number\", \"segment_index\"])\n",
    "                   .head(1)\n",
    "                   .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        all_results.append(df_top1)\n",
    "        print(f\"âœ… å®Œæˆæ¨ç†: {number}, æœ‰æ•ˆç‰‡æ®µæ•°: {len(df_top1)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ¨ç†å¤±è´¥: {file_path}, é”™è¯¯: {e}\")\n",
    "\n",
    "# åˆå¹¶ç»“æœå¹¶æ’åºä¿å­˜\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    final_df = final_df.sort_values(by=[\"number\", \"segment_index\"]).reset_index(drop=True)\n",
    "    final_df.to_csv(OUTPUT_CSV_SORTED, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… æ¨ç†å’Œæ’åºå®Œæˆï¼Œæœ€ç»ˆç»“æœä¿å­˜è‡³: {OUTPUT_CSV_SORTED}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ— æœ‰æ•ˆæ¨ç†ç»“æœç”Ÿæˆ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¿®æ­£label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¿®æ­£åçš„ train list å·²ä¿å­˜è‡³: E:/AMR/DA/Projekt/data/data_list/0408/all_data_meta_allTypes_high_quality.csv\n",
      "ğŸ¯ ä¿ç•™æ ·æœ¬æ•°: 102147 / åŸå§‹æ ·æœ¬æ•°: 186980\n",
      "âŒ èˆå¼ƒæ ·æœ¬æ•°ï¼ˆé¢„æµ‹ç¼ºå¤± & ä¸ä¸€è‡´ï¼‰: 84833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "TRAIN_CSV = f\"{root_data_path}/all_data_meta_allTypes.csv\"\n",
    "BIRDNET_CSV = f\"{root_data_path}/birdnet_all_predictions_sorted.csv\"\n",
    "OUTPUT_CSV = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "birdnet_df = pd.read_csv(BIRDNET_CSV)\n",
    "\n",
    "# === âœ… æ›¿æ¢åç§°ï¼šå°† \"Common Blackbird\" ç»Ÿä¸€æ”¹ä¸º \"Eurasian Blackbird\"\n",
    "train_df[\"bird_name\"] = train_df[\"bird_name\"].replace(\"Common Blackbird\", \"Eurasian Blackbird\")\n",
    "\n",
    "# === ç»Ÿä¸€å°å†™ä»¥ä¾¿å¯¹æ¯”\n",
    "train_df[\"bird_name_lower\"] = train_df[\"bird_name\"].str.lower()\n",
    "birdnet_df[\"common_name_lower\"] = birdnet_df[\"common_name\"].str.lower()\n",
    "\n",
    "# === åˆå¹¶ä¸¤ä¸ªè¡¨æ ¼ï¼ˆæŒ‰ number å’Œ segment_index åŒ¹é…ï¼‰\n",
    "merged = train_df.merge(\n",
    "    birdnet_df,\n",
    "    how=\"left\",\n",
    "    on=[\"number\", \"segment_index\"]\n",
    ")\n",
    "\n",
    "# === æ¡ä»¶ 1ï¼šBirdNET æœ‰ç»“æœ ä¸” label ä¸€è‡´\n",
    "condition1 = (merged[\"common_name_lower\"].notna()) & (merged[\"bird_name_lower\"] == merged[\"common_name_lower\"])\n",
    "\n",
    "# === æ¡ä»¶ 2ï¼šæ ‡æ³¨ä¸º Background Noiseï¼ˆç›´æ¥ä¿ç•™ï¼‰\n",
    "condition2 = (merged[\"bird_name\"] == \"Background Noise\")\n",
    "\n",
    "# === æ»¡è¶³ä»»ä¸€æ¡ä»¶å³å¯ä¿ç•™\n",
    "cleaned_df = merged[condition1 | condition2]\n",
    "\n",
    "# === å¯¼å‡ºåŸå§‹å­—æ®µ\n",
    "cleaned_train_df = cleaned_df[train_df.columns]\n",
    "cleaned_train_df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# === è¾“å‡ºä¿¡æ¯\n",
    "print(f\"âœ… ä¿®æ­£åçš„ train list å·²ä¿å­˜è‡³: {OUTPUT_CSV}\")\n",
    "print(f\"ğŸ¯ ä¿ç•™æ ·æœ¬æ•°: {len(cleaned_train_df)} / åŸå§‹æ ·æœ¬æ•°: {len(train_df)}\")\n",
    "print(f\"âŒ èˆå¼ƒæ ·æœ¬æ•°ï¼ˆé¢„æµ‹ç¼ºå¤± & ä¸ä¸€è‡´ï¼‰: {len(train_df) - len(cleaned_train_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¯¹æ¯”æ–°æ—§æ ‡ç­¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ç±»åˆ«æ€»æ•°ï¼ˆæ—§æ•°æ®ï¼‰: 33\n",
      "ğŸ“Š ç±»åˆ«æ€»æ•°ï¼ˆæ–°æ•°æ®ï¼‰: 33\n",
      "\n",
      "âœ… æ‰€æœ‰ç±»åˆ«å‡æœ‰ä¿ç•™\n",
      "\n",
      "ğŸ“Š ç±»åˆ«æ•°é‡å¯¹æ¯”ï¼š\n",
      "                          Old Count  New Count\n",
      "bird_name                                     \n",
      "Background Noise               3000       3000\n",
      "Black-headed Gull              4398       2800\n",
      "Canada Goose                   4924       3065\n",
      "Carrion Crow                   5400       1893\n",
      "Common Chaffinch               7961       3375\n",
      "Common Kingfisher              3117       1808\n",
      "Common Redstart                4921       2280\n",
      "Dunnock                        4307       2854\n",
      "Eurasian Blackbird             8219       4459\n",
      "Eurasian Blackcap             10771       4726\n",
      "Eurasian Blue Tit              5793       3285\n",
      "Eurasian Bullfinch             4818       3035\n",
      "Eurasian Coot                  4512       2576\n",
      "Eurasian Golden Oriole         5066       2980\n",
      "Eurasian Jay                   9214       2988\n",
      "Eurasian Nuthatch              5203       3058\n",
      "Eurasian Siskin                5495       4145\n",
      "Eurasian Treecreeper           4995       2399\n",
      "Eurasian Wren                  8137       4158\n",
      "European Goldfinch             4387       3320\n",
      "European Robin                 8929       4616\n",
      "Goldcrest                      4650       2713\n",
      "Great Spotted Woodpecker       4103       2769\n",
      "Great Tit                      6921       2659\n",
      "Hawfinch                       4135       2969\n",
      "Hooded Crow                    8236       2342\n",
      "Long-tailed Tit                7175       5138\n",
      "Mallard                        4034       2371\n",
      "Marsh Tit                      4690       2801\n",
      "Redwing                        4850       3518\n",
      "Rook                           4143       3267\n",
      "Short-toed Treecreeper         5186       3020\n",
      "Stock Dove                     5290       1760\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "old_csv_path = f\"{root_data_path}/all_data_meta_allTypes.csv\"\n",
    "new_csv_path = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "\n",
    "# === è¯»å– CSV æ–‡ä»¶ ===\n",
    "df_old = pd.read_csv(old_csv_path)\n",
    "df_new = pd.read_csv(new_csv_path)\n",
    "\n",
    "# === âœ… æ›¿æ¢ç±»åˆ«åç§°ï¼šCommon Blackbird â†’ Eurasian Blackbird\n",
    "df_old[\"bird_name\"] = df_old[\"bird_name\"].replace(\"Common Blackbird\", \"Eurasian Blackbird\")\n",
    "\n",
    "# === è·å–ç±»åˆ«åˆ†å¸ƒ ===\n",
    "old_counts = df_old[\"bird_name\"].value_counts().sort_index()\n",
    "new_counts = df_new[\"bird_name\"].value_counts().sort_index()\n",
    "\n",
    "# === åˆå¹¶å¯¹æ¯”è¡¨ ===\n",
    "compare_df = pd.DataFrame({\n",
    "    \"Old Count\": old_counts,\n",
    "    \"New Count\": new_counts\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# === æ‰“å°ç±»åˆ«æ€»æ•°ä¿¡æ¯ ===\n",
    "num_classes_old = compare_df[\"Old Count\"].astype(bool).sum()\n",
    "num_classes_new = compare_df[\"New Count\"].astype(bool).sum()\n",
    "\n",
    "print(f\"\\nğŸ“Š ç±»åˆ«æ€»æ•°ï¼ˆæ—§æ•°æ®ï¼‰: {num_classes_old}\")\n",
    "print(f\"ğŸ“Š ç±»åˆ«æ€»æ•°ï¼ˆæ–°æ•°æ®ï¼‰: {num_classes_new}\")\n",
    "\n",
    "# === æ‰“å°ç¼ºå¤±ç±»åˆ«ï¼ˆåœ¨æ–°æ•°æ®ä¸­ä¸º0çš„ï¼‰\n",
    "missing_classes = compare_df[compare_df[\"New Count\"] == 0]\n",
    "if not missing_classes.empty:\n",
    "    print(f\"\\nâŒ ä»¥ä¸‹ {len(missing_classes)} ä¸ªç±»åˆ«åœ¨ç²¾ä¿®åè¢«å®Œå…¨å‰”é™¤ï¼š\")\n",
    "    print(missing_classes)\n",
    "else:\n",
    "    print(\"\\nâœ… æ‰€æœ‰ç±»åˆ«å‡æœ‰ä¿ç•™\")\n",
    "\n",
    "# === æ‰“å°ç±»åˆ«æ•°é‡å¯¹æ¯”è¡¨ ===\n",
    "print(\"\\nğŸ“Š ç±»åˆ«æ•°é‡å¯¹æ¯”ï¼š\")\n",
    "print(compare_df)\n",
    "\n",
    "# # === ä¿å­˜å¯¹æ¯”è¡¨ ===\n",
    "# output_path = \"E:/AMR/DA/Projekt/data/data_list/0401/class_distribution_comparison_fixed.csv\"\n",
    "# compare_df.to_csv(output_path, encoding=\"utf-8-sig\")\n",
    "# print(f\"\\nâœ… åˆ†å¸ƒå¯¹æ¯”è¡¨å·²ä¿å­˜è‡³: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒé›†ä¿å­˜è‡³: E:/AMR/DA/Projekt/data/data_list/0408/train_list_high_quality.csvï¼Œå…± 92247 æ¡\n",
      "âœ… æµ‹è¯•é›†ä¿å­˜è‡³: E:/AMR/DA/Projekt/data/data_list/0408/valid_list_high_quality.csvï¼Œå…± 9900 æ¡\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "INPUT_CSV = f\"{root_data_path}/all_data_meta_allTypes_high_quality.csv\"\n",
    "TRAIN_CSV = f\"{root_data_path}/train_list_high_quality.csv\"\n",
    "TEST_CSV = f\"{root_data_path}/valid_list_high_quality.csv\"\n",
    "Valid_Num = 300\n",
    "\n",
    "# === è¯»å–æ•°æ® ===\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# âœ… åˆ†å‡º Background Noise ä¸å…¶ä»–ç±»åˆ«\n",
    "is_bg = df[\"bird_name\"] == \"Background Noise\"\n",
    "bg_df = df[is_bg & df[\"segment_index\"].isin([0, 1, 2])].copy()\n",
    "non_bg_df = df[~is_bg].copy()\n",
    "\n",
    "# === åˆå§‹åŒ–å®¹å™¨\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# âœ… å¤„ç†é Background Noise ç±»åˆ«\n",
    "for bird in non_bg_df[\"bird_name\"].unique():\n",
    "    class_df = non_bg_df[non_bg_df[\"bird_name\"] == bird]\n",
    "    grouped = class_df.groupby(\"number\")\n",
    "    groups = list(grouped.groups.items())\n",
    "\n",
    "    test_samples = []\n",
    "    used_numbers = set()\n",
    "    total_test_segments = 0\n",
    "    target_segments = Valid_Num\n",
    "\n",
    "    for number, indices in groups:\n",
    "        group_samples = class_df.loc[indices]\n",
    "        group_len = len(group_samples)\n",
    "\n",
    "        # ç²¾ç¡®æ§åˆ¶æµ‹è¯•é›†å¤§å°\n",
    "        if group_len <= (target_segments - total_test_segments):\n",
    "            test_samples.append(group_samples)\n",
    "            used_numbers.add(number)\n",
    "            total_test_segments += group_len\n",
    "        if total_test_segments >= target_segments:\n",
    "            break\n",
    "\n",
    "    if test_samples:\n",
    "        test_df = pd.concat(test_samples)\n",
    "        test_list.append(test_df)\n",
    "        train_df = class_df[~class_df[\"number\"].isin(used_numbers)]\n",
    "        train_list.append(train_df)\n",
    "\n",
    "# âœ… ç²¾å‡†åˆ’åˆ† Background Noiseï¼ˆseg0~2ï¼‰\n",
    "bg_grouped = bg_df.groupby(\"number\")\n",
    "bg_test, bg_train = [], []\n",
    "total_bg_test = 0\n",
    "target_bg_test = Valid_Num\n",
    "\n",
    "for number, group in bg_grouped:\n",
    "    group = group[group[\"segment_index\"].isin([0, 1, 2])]\n",
    "    group_len = len(group)\n",
    "\n",
    "    if total_bg_test + group_len <= target_bg_test:\n",
    "        bg_test.append(group)\n",
    "        total_bg_test += group_len\n",
    "    else:\n",
    "        bg_train.append(group)\n",
    "\n",
    "# === åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•é›†\n",
    "final_train = pd.concat(train_list + bg_train).reset_index(drop=True)\n",
    "final_test = pd.concat(test_list + bg_test).reset_index(drop=True)\n",
    "\n",
    "# === ä¿å­˜ç»“æœ\n",
    "final_train.to_csv(TRAIN_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "final_test.to_csv(TEST_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… è®­ç»ƒé›†ä¿å­˜è‡³: {TRAIN_CSV}ï¼Œå…± {len(final_train)} æ¡\")\n",
    "print(f\"âœ… æµ‹è¯•é›†ä¿å­˜è‡³: {TEST_CSV}ï¼Œå…± {len(final_test)} æ¡\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¸¤ä¸ªåˆ—è¡¨ä¸­çš„é¸Ÿç±»å®Œå…¨ä¸é‡å¤ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === é…ç½®è·¯å¾„ ===\n",
    "CSV_1_PATH = f\"{root_data_path}/train_list_high_quality.csv\"\n",
    "CSV_2_PATH = f\"{root_data_path}/valid_list_high_quality.csv\"\n",
    "\n",
    "# === è¯»å– CSV ===\n",
    "df1 = pd.read_csv(CSV_1_PATH)\n",
    "df2 = pd.read_csv(CSV_2_PATH)\n",
    "\n",
    "# === æå– bird_name é›†åˆ\n",
    "birds_1 = set(df1[\"number\"].unique())\n",
    "birds_2 = set(df2[\"number\"].unique())\n",
    "\n",
    "# === æŸ¥æ‰¾äº¤é›†\n",
    "common_birds = birds_1.intersection(birds_2)\n",
    "\n",
    "# === æ‰“å°ç»“æœ\n",
    "if common_birds:\n",
    "    print(f\"âš ï¸ ä¸¤ä¸ª CSV å­˜åœ¨ {len(common_birds)} ä¸ªé‡å¤çš„é¸Ÿç±»ï¼š\")\n",
    "    for bird in sorted(common_birds):\n",
    "        print(\" -\", bird)\n",
    "else:\n",
    "    print(\"âœ… ä¸¤ä¸ªåˆ—è¡¨ä¸­çš„é¸Ÿç±»å®Œå…¨ä¸é‡å¤ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
