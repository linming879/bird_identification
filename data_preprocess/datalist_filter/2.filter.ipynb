{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Audios -> wav Audios\n",
    "Audio files ori -> Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# è®¾å®šåŸå§‹å’Œç›®æ ‡æ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„\n",
    "src_base_dir = \"E:/AMR/DA/Projekt/data/Audio_files_ori\"  # åŸå§‹æ–‡ä»¶å¤¹\n",
    "dst_base_dir = \"E:/AMR/DA/Projekt/data/Audio_files\"  # ç›®æ ‡æ–‡ä»¶å¤¹\n",
    "\n",
    "# ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨\n",
    "os.makedirs(dst_base_dir, exist_ok=True)\n",
    "\n",
    "# æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… XC ç¼–å·æ ¼å¼ï¼Œä¾‹å¦‚ \"XC123456\"\n",
    "xc_pattern = re.compile(r\"(XC\\d+)\")\n",
    "\n",
    "# éå†åŸå§‹æ–‡ä»¶å¤¹\n",
    "for folder in os.listdir(src_base_dir):\n",
    "    src_folder_path = os.path.join(src_base_dir, folder)\n",
    "    dst_folder_path = os.path.join(dst_base_dir, folder)\n",
    "\n",
    "    # ç¡®ä¿ç›®æ ‡å­æ–‡ä»¶å¤¹å­˜åœ¨\n",
    "    os.makedirs(dst_folder_path, exist_ok=True)\n",
    "\n",
    "    # ç¡®ä¿æ˜¯æ–‡ä»¶å¤¹\n",
    "    if os.path.isdir(src_folder_path):\n",
    "        for file in os.listdir(src_folder_path):\n",
    "            if file.endswith((\".mp3\", \".ogg\", \".wav\")):  # å¤„ç†éŸ³é¢‘æ–‡ä»¶\n",
    "                match = xc_pattern.search(file)  # æå– XC ç¼–å·\n",
    "                if match:\n",
    "                    number = match.group(1)  # åªä¿ç•™ \"XC123456\"\n",
    "                    new_filename = f\"{number}.wav\"  # ç»Ÿä¸€æ”¹ä¸º \"XC123456.wav\"\n",
    "\n",
    "                    # åŸå§‹æ–‡ä»¶è·¯å¾„å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„\n",
    "                    src_file_path = os.path.join(src_folder_path, file)\n",
    "                    dst_file_path = os.path.join(dst_folder_path, new_filename)\n",
    "\n",
    "                    # å¤åˆ¶å¹¶é‡å‘½å\n",
    "                    shutil.copy2(src_file_path, dst_file_path)\n",
    "                    print(f\"å·²å¤„ç†: {src_file_path} -> {dst_file_path}\")\n",
    "\n",
    "print(\"æ‰€æœ‰æ–‡ä»¶å·²é‡å‘½åå¹¶ç§»åŠ¨è‡³ç›®æ ‡æ–‡ä»¶å¤¹ï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta csv Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è·³è¿‡æ–‡ä»¶å¤¹ï¼šaudio_file_counts.csvï¼Œå‘½åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ\n",
      "CSV æ–‡ä»¶å·²ä¿å­˜è‡³ E:/AMR/DA/Projekt/data/Audio_files/train_meta_100.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# è®¾ç½®æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„\n",
    "base_dir = \"E:/AMR/DA/Projekt/data/Audio_files\"  # è¿™é‡Œå¯ä»¥æ”¹æˆä½ çš„å®é™…è·¯å¾„\n",
    "\n",
    "# ç”¨äºå­˜å‚¨æ•°æ®\n",
    "data = []\n",
    "\n",
    "# éå† Audio_files æ–‡ä»¶å¤¹\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # åªå¤„ç†æ–‡ä»¶å¤¹\n",
    "    if os.path.isdir(folder_path):\n",
    "        # è§£ææ–‡ä»¶å¤¹åç§°ï¼Œè·å– vocalization å’Œ bird_name\n",
    "        parts = folder.split(\" - \")\n",
    "        if len(parts) != 2:\n",
    "            print(f\"è·³è¿‡æ–‡ä»¶å¤¹ï¼š{folder}ï¼Œå‘½åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ\")\n",
    "            continue\n",
    "        \n",
    "        vocalization, bird_name = parts\n",
    "        \n",
    "        # éå†è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):  # åªå¤„ç† .wav æ–‡ä»¶\n",
    "                number = file.replace(\".wav\", \"\")  # æå– XC ç¼–å·\n",
    "                full_path = os.path.join(folder_path, file)  # è®°å½•å®Œæ•´è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰\n",
    "                full_path = full_path.replace(\"\\\\\", \"/\")  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦\n",
    "                data.append([bird_name, vocalization, number, full_path])\n",
    "\n",
    "# åˆ›å»º DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"bird_name\", \"vocalization\", \"number\", \"path\"])\n",
    "\n",
    "# ä¿å­˜ CSV\n",
    "csv_path = \"E:/AMR/DA/Projekt/data/Audio_files/train_meta_100.csv\"\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"CSV æ–‡ä»¶å·²ä¿å­˜è‡³ {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Split, Spectogram and all data meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import cv2\n",
    "import math\n",
    "import cupy as cp\n",
    "from cupyx.scipy import signal as cupy_signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "class config:\n",
    "    SEED = 2024\n",
    "    DEVICE = 'cpu'\n",
    "    OUTPUT_DIR = \"E:/AMR/DA/Projekt/data/Audio_spec\"  # å­˜å‚¨é¢‘è°±æ•°æ®\n",
    "    FS = 32000  # é‡‡æ ·ç‡\n",
    "    N_FFT = 1095  # FFT ç‚¹æ•°\n",
    "    WIN_SIZE = 412  # é¢‘è°±çª—å£å¤§å°\n",
    "    WIN_LAP = 100  # é¢‘è°±çª—å£é‡å å¤§å°\n",
    "    MIN_FREQ = 40  # æœ€å°é¢‘ç‡\n",
    "    MAX_FREQ = 15000  # æœ€å¤§é¢‘ç‡\n",
    "    SEGMENT_DURATION = 3  # æ¯æ®µ 3 ç§’\n",
    "    SPEC_SIZE = (256, 256)  # é¢‘è°±å›¾å¤§å° (å®½, é«˜)\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# è¯»å– train_meta.csv\n",
    "csv_path = \"E:/AMR/DA/Projekt/data/Audio_files/train_meta_100_deduplicated.csv\"\n",
    "train_df = pd.read_csv(csv_path)\n",
    "\n",
    "# é¢‘è°±è½¬æ¢å‡½æ•°\n",
    "def oog2spec_via_cupy(audio_data):\n",
    "    audio_data = cp.array(audio_data)\n",
    "    \n",
    "    # å¤„ç† NaN æ•°æ®\n",
    "    mean_signal = cp.nanmean(audio_data)\n",
    "    audio_data = cp.nan_to_num(audio_data, nan=mean_signal) if cp.isnan(audio_data).mean() < 1 else cp.zeros_like(audio_data)\n",
    "    \n",
    "    # è®¡ç®—é¢‘è°±\n",
    "    frequencies, times, spec_data = cupy_signal.spectrogram(\n",
    "        audio_data, \n",
    "        fs=config.FS, \n",
    "        nfft=config.N_FFT, \n",
    "        nperseg=config.WIN_SIZE, \n",
    "        noverlap=config.WIN_LAP, \n",
    "        window='hann'\n",
    "    )\n",
    "\n",
    "    # è¿‡æ»¤é¢‘ç‡èŒƒå›´\n",
    "    valid_freq = (frequencies >= config.MIN_FREQ) & (frequencies <= config.MAX_FREQ)\n",
    "    spec_data = spec_data[valid_freq, :]\n",
    "    \n",
    "    # å¯¹æ•°å˜æ¢å’Œå½’ä¸€åŒ–\n",
    "    spec_data = cp.log10(spec_data + 1e-20)\n",
    "    spec_data = spec_data - spec_data.min()\n",
    "    spec_data = spec_data / spec_data.max()\n",
    "    \n",
    "    return spec_data.get()\n",
    "\n",
    "# ç”¨äºå­˜å‚¨å¤„ç†åçš„æ•°æ®\n",
    "all_data = []\n",
    "\n",
    "# å¤„ç†éŸ³é¢‘æ•°æ®\n",
    "for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    file_path = row[\"path\"]\n",
    "    bird_name = row[\"bird_name\"]\n",
    "    vocalization = row[\"vocalization\"]\n",
    "    number = row[\"number\"]\n",
    "\n",
    "    # è¯»å–éŸ³é¢‘\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(file_path, sr=config.FS)\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½å¤±è´¥: {file_path}, é”™è¯¯: {e}\")\n",
    "        continue\n",
    "\n",
    "    # è®¡ç®—éŸ³é¢‘æ€»æ—¶é•¿\n",
    "    total_duration = len(audio_data) / config.FS\n",
    "\n",
    "    # æŒ‰ 3s åˆ†å‰²éŸ³é¢‘\n",
    "    num_segments = math.floor(total_duration / config.SEGMENT_DURATION)\n",
    "\n",
    "    for seg_idx in range(num_segments):\n",
    "        start_idx = seg_idx * config.SEGMENT_DURATION * config.FS\n",
    "        end_idx = start_idx + config.SEGMENT_DURATION * config.FS\n",
    "        segment_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "        # è½¬æ¢ä¸ºé¢‘è°±å›¾\n",
    "        spec_data = oog2spec_via_cupy(segment_audio)\n",
    "\n",
    "        # è°ƒæ•´å°ºå¯¸\n",
    "        spec_data = cv2.resize(spec_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # ä¿å­˜é¢‘è°±æ•°æ®\n",
    "        spec_filename = f\"{number}_seg{seg_idx}.npy\"\n",
    "        spec_filepath = os.path.join(config.OUTPUT_DIR, spec_filename)\n",
    "        np.save(spec_filepath, spec_data.astype(np.float32))\n",
    "\n",
    "        # è®°å½•æ•°æ®\n",
    "        all_data.append([bird_name, vocalization, number, seg_idx, spec_filepath])\n",
    "\n",
    "# ç”Ÿæˆ all_data_meta.csv\n",
    "meta_df = pd.DataFrame(all_data, columns=[\"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"path\"])\n",
    "meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta.csv\"\n",
    "meta_df.to_csv(meta_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"æ‰€æœ‰éŸ³é¢‘å¤„ç†å®Œæˆï¼Œé¢‘è°±å›¾å­˜å‚¨åœ¨ {config.OUTPUT_DIR}\")\n",
    "print(f\"å…ƒæ•°æ® CSV æ–‡ä»¶å·²ä¿å­˜è‡³ {meta_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–°ç‰ˆç”Ÿæˆspecå’Œmelï¼Œ512 256çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\40920\\.conda\\envs\\testenv\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n",
      "  5%|â–Œ         | 421/7844 [01:52<24:08,  5.12it/s]  C:\\Users\\40920\\AppData\\Local\\Temp\\ipykernel_153280\\3010258197.py:96: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, _ = librosa.load(file_path, sr=config.FS)\n",
      "c:\\Users\\40920\\.conda\\envs\\testenv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 22%|â–ˆâ–ˆâ–       | 1692/7844 [09:27<19:42,  5.20it/s]  C:\\Users\\40920\\AppData\\Local\\Temp\\ipykernel_153280\\3010258197.py:82: RuntimeWarning: invalid value encountered in divide\n",
      "  mel_spec = mel_spec / mel_spec.max()\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7844/7844 [48:57<00:00,  2.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰éŸ³é¢‘å¤„ç†å®Œæˆï¼\n",
      "ğŸ“ çº¿æ€§é¢‘è°±å›¾å­˜å‚¨äº: E:/AMR/DA/Projekt/data/Audio_spec_paperstyle\n",
      "ğŸ“ Mel é¢‘è°±å›¾å­˜å‚¨äº: E:/AMR/DA/Projekt/data/Audio_spec_mel\n",
      "ğŸ“ å…ƒæ•°æ® CSV æ–‡ä»¶å·²ä¿å­˜è‡³: E:/AMR/DA/Projekt/data/all_data_meta.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import cv2\n",
    "import math\n",
    "import cupy as cp\n",
    "from cupyx.scipy import signal as cupy_signal\n",
    "from tqdm import tqdm\n",
    "# é…ç½®å‚æ•°\n",
    "# class config:\n",
    "#     SEED = 2024\n",
    "#     DEVICE = 'cpu'\n",
    "#     OUTPUT_DIR = \"E:/AMR/DA/Projekt/data/Audio_spec\"  # å­˜å‚¨é¢‘è°±æ•°æ®\n",
    "#     FS = 32000  # é‡‡æ ·ç‡\n",
    "#     N_FFT = 1095  # FFT ç‚¹æ•°\n",
    "#     WIN_SIZE = 412  # é¢‘è°±çª—å£å¤§å°\n",
    "#     WIN_LAP = 100  # é¢‘è°±çª—å£é‡å å¤§å°\n",
    "#     MIN_FREQ = 40  # æœ€å°é¢‘ç‡\n",
    "#     MAX_FREQ = 15000  # æœ€å¤§é¢‘ç‡\n",
    "#     SEGMENT_DURATION = 3  # æ¯æ®µ 3 ç§’\n",
    "#     SPEC_SIZE = (256, 256)  # é¢‘è°±å›¾å¤§å° (å®½, é«˜)\n",
    "# é…ç½®å‚æ•°\n",
    "class config:\n",
    "    SEED = 2024\n",
    "    DEVICE = 'cpu'\n",
    "    OUTPUT_DIR_SPEC = \"E:/AMR/DA/Projekt/data/Audio_spec_paperstyle\"  # çº¿æ€§é¢‘è°±å›¾ç›®å½•\n",
    "    OUTPUT_DIR_MEL = \"E:/AMR/DA/Projekt/data/Audio_spec_mel\"         # melé¢‘è°±å›¾ç›®å½•\n",
    "    FS = 48000\n",
    "    N_FFT = 512\n",
    "    WIN_SIZE = 512\n",
    "    WIN_LAP = 384\n",
    "    MIN_FREQ = 150\n",
    "    MAX_FREQ = 15000\n",
    "    SEGMENT_DURATION = 3\n",
    "    SPEC_SIZE = (512, 256)  # (å®½, é«˜)\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(config.OUTPUT_DIR_SPEC, exist_ok=True)\n",
    "os.makedirs(config.OUTPUT_DIR_MEL, exist_ok=True)\n",
    "\n",
    "# è¯»å– train_meta.csv\n",
    "csv_path = \"E:/AMR/DA/Projekt/data/Audio_files/train_meta_100_deduplicated.csv\"\n",
    "train_df = pd.read_csv(csv_path)\n",
    "\n",
    "# çº¿æ€§é¢‘è°±å›¾ï¼ˆvia cupyï¼‰\n",
    "def oog2spec_via_cupy(audio_data):\n",
    "    audio_data = cp.array(audio_data)\n",
    "    mean_signal = cp.nanmean(audio_data)\n",
    "    audio_data = cp.nan_to_num(audio_data, nan=mean_signal) if cp.isnan(audio_data).mean() < 1 else cp.zeros_like(audio_data)\n",
    "    \n",
    "    frequencies, times, spec_data = cupy_signal.spectrogram(\n",
    "        audio_data,\n",
    "        fs=config.FS,\n",
    "        nfft=config.N_FFT,\n",
    "        nperseg=config.WIN_SIZE,\n",
    "        noverlap=config.WIN_LAP,\n",
    "        window='hann'\n",
    "    )\n",
    "    valid_freq = (frequencies >= config.MIN_FREQ) & (frequencies <= config.MAX_FREQ)\n",
    "    spec_data = spec_data[valid_freq, :]\n",
    "    spec_data = cp.log10(spec_data + 1e-20)\n",
    "    spec_data = spec_data - spec_data.min()\n",
    "    spec_data = spec_data / spec_data.max()\n",
    "    return spec_data.get()\n",
    "\n",
    "# æ–°å¢ï¼šmel é¢‘è°±å›¾\n",
    "def audio2mel(audio_data):\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.N_FFT - config.WIN_LAP,\n",
    "        win_length=config.WIN_SIZE,\n",
    "        window='hann',\n",
    "        n_mels=64,\n",
    "        fmin=config.MIN_FREQ,\n",
    "        fmax=config.MAX_FREQ\n",
    "    )\n",
    "    mel_spec = np.log10(mel_spec + 1e-9)\n",
    "    mel_spec = mel_spec - mel_spec.min()\n",
    "    mel_spec = mel_spec / mel_spec.max()\n",
    "    return mel_spec\n",
    "\n",
    "# å­˜å‚¨å¤„ç†ç»“æœ\n",
    "all_data = []\n",
    "\n",
    "# ä¸»å¤„ç†å¾ªç¯\n",
    "for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    file_path = row[\"path\"]\n",
    "    bird_name = row[\"bird_name\"]\n",
    "    vocalization = row[\"vocalization\"]\n",
    "    number = row[\"number\"]\n",
    "\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(file_path, sr=config.FS)\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½å¤±è´¥: {file_path}, é”™è¯¯: {e}\")\n",
    "        continue\n",
    "\n",
    "    total_duration = len(audio_data) / config.FS\n",
    "    num_segments = math.floor(total_duration / config.SEGMENT_DURATION)\n",
    "\n",
    "    for seg_idx in range(num_segments):\n",
    "        start_idx = seg_idx * config.SEGMENT_DURATION * config.FS\n",
    "        end_idx = start_idx + config.SEGMENT_DURATION * config.FS\n",
    "        segment_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "        # â¤ ç”Ÿæˆçº¿æ€§é¢‘è°±å›¾\n",
    "        spec_data = oog2spec_via_cupy(segment_audio)\n",
    "        spec_data = cv2.resize(spec_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        spec_filename = f\"{number}_seg{seg_idx}.npy\"\n",
    "        spec_filepath = os.path.join(config.OUTPUT_DIR_SPEC, spec_filename)\n",
    "        np.save(spec_filepath, spec_data.astype(np.float32))\n",
    "\n",
    "        # â¤ ç”Ÿæˆ mel é¢‘è°±å›¾\n",
    "        mel_data = audio2mel(segment_audio)\n",
    "        mel_data = cv2.resize(mel_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        mel_filename = f\"{number}_seg{seg_idx}_mel.npy\"\n",
    "        mel_filepath = os.path.join(config.OUTPUT_DIR_MEL, mel_filename)\n",
    "        np.save(mel_filepath, mel_data.astype(np.float32))\n",
    "\n",
    "        # â¤ è®°å½•è·¯å¾„ä¿¡æ¯\n",
    "        all_data.append([bird_name, vocalization, number, seg_idx, spec_filepath, mel_filepath])\n",
    "\n",
    "# ä¿å­˜å…ƒæ•°æ®\n",
    "meta_df = pd.DataFrame(all_data, columns=[\n",
    "    \"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"spec_path\", \"mel_path\"\n",
    "])\n",
    "meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta.csv\"\n",
    "meta_df.to_csv(meta_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… æ‰€æœ‰éŸ³é¢‘å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"ğŸ“ çº¿æ€§é¢‘è°±å›¾å­˜å‚¨äº: {config.OUTPUT_DIR_SPEC}\")\n",
    "print(f\"ğŸ“ Mel é¢‘è°±å›¾å­˜å‚¨äº: {config.OUTPUT_DIR_MEL}\")\n",
    "print(f\"ğŸ“ å…ƒæ•°æ® CSV æ–‡ä»¶å·²ä¿å­˜è‡³: {meta_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ•´åˆfreefield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "source_dir = \"E:/AMR/DA/Projekt/data/freefield1010\"  # åŸå§‹ç›®å½•\n",
    "target_dir = \"E:/AMR/DA/Projekt/data/negative_audio\"  # ç›®æ ‡ç›®å½•\n",
    "\n",
    "# ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# éå†åŸå§‹ç›®å½•åŠå…¶å­ç›®å½•\n",
    "for root, _, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):  # åªå¤„ç† .wav æ–‡ä»¶\n",
    "            source_file = os.path.join(root, file)  # æºæ–‡ä»¶è·¯å¾„\n",
    "            target_file = os.path.join(target_dir, file)  # ç›®æ ‡æ–‡ä»¶è·¯å¾„\n",
    "\n",
    "            # å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰è¿™ä¸ªæ–‡ä»¶ï¼Œåˆ™å¤åˆ¶\n",
    "            if not os.path.exists(target_file):\n",
    "                shutil.copy2(source_file, target_file)  # ä½¿ç”¨ copy2 ä¿ç•™æ–‡ä»¶çš„åŸå§‹å…ƒæ•°æ®\n",
    "                print(f\"å¤åˆ¶ {source_file} åˆ° {target_file}\")\n",
    "            else:\n",
    "                print(f\"è·³è¿‡ {file}ï¼Œç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ã€‚\")\n",
    "\n",
    "print(\"éŸ³é¢‘æ–‡ä»¶ä¼ è¾“å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Negative Samples from freefield1010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import cv2\n",
    "import math\n",
    "import cupy as cp\n",
    "from cupyx.scipy import signal as cupy_signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "class config:\n",
    "    SEED = 2024\n",
    "    DEVICE = 'cpu'\n",
    "    OUTPUT_DIR = \"E:/AMR/DA/Projekt/data/Audio_spec\"  # å­˜å‚¨é¢‘è°±æ•°æ®\n",
    "    FS = 32000  # é‡‡æ ·ç‡\n",
    "    N_FFT = 1095  # FFT ç‚¹æ•°\n",
    "    WIN_SIZE = 412  # é¢‘è°±çª—å£å¤§å°\n",
    "    WIN_LAP = 100  # é¢‘è°±çª—å£é‡å å¤§å°\n",
    "    MIN_FREQ = 40  # æœ€å°é¢‘ç‡\n",
    "    MAX_FREQ = 15000  # æœ€å¤§é¢‘ç‡\n",
    "    SEGMENT_DURATION = 3  # æ¯æ®µ 3 ç§’\n",
    "    SPEC_SIZE = (256, 256)  # é¢‘è°±å›¾å¤§å° (å®½, é«˜)\n",
    "    MAX_NEGATIVE_SAMPLES = 3500  # æœ€å¤§è´Ÿæ ·æœ¬æ•°é‡\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# é¢‘è°±è½¬æ¢å‡½æ•°\n",
    "def oog2spec_via_cupy(audio_data):\n",
    "    if len(audio_data) == 0:\n",
    "        print(\"âš ï¸ è­¦å‘Šï¼šéŸ³é¢‘æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è¯¥æ–‡ä»¶ã€‚\")\n",
    "        return None\n",
    "    \n",
    "    audio_data = cp.array(audio_data)\n",
    "    \n",
    "    # è®¡ç®—é¢‘è°±\n",
    "    frequencies, times, spec_data = cupy_signal.spectrogram(\n",
    "        audio_data, \n",
    "        fs=config.FS, \n",
    "        nfft=config.N_FFT, \n",
    "        nperseg=config.WIN_SIZE, \n",
    "        noverlap=config.WIN_LAP, \n",
    "        window='hann'\n",
    "    )\n",
    "\n",
    "    # è¿‡æ»¤é¢‘ç‡èŒƒå›´\n",
    "    valid_freq = (frequencies >= config.MIN_FREQ) & (frequencies <= config.MAX_FREQ)\n",
    "    spec_data = spec_data[valid_freq, :]\n",
    "    \n",
    "    # å¯¹æ•°å˜æ¢å’Œå½’ä¸€åŒ–\n",
    "    spec_data = cp.log10(spec_data + 1e-20)\n",
    "    spec_data = spec_data - spec_data.min()\n",
    "    spec_data = spec_data / spec_data.max()\n",
    "    \n",
    "    return spec_data.get()\n",
    "\n",
    "# å¤„ç†èƒŒæ™¯å™ªéŸ³ï¼ˆnegative samplesï¼‰æ•°æ®\n",
    "negative_samples_dir = \"E:/AMR/DA/Projekt/data/negative_audio\"  # èƒŒæ™¯å™ªéŸ³éŸ³é¢‘ç›®å½•\n",
    "negative_samples_processed = 0\n",
    "negative_data = []  # å­˜å‚¨è´Ÿæ ·æœ¬ä¿¡æ¯\n",
    "\n",
    "for root, _, files in os.walk(negative_samples_dir):\n",
    "    for file in tqdm(files, desc=\"Processing Negative Audio Files\"):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            try:\n",
    "                # åŠ è½½éŸ³é¢‘\n",
    "                audio_data, _ = librosa.load(file_path, sr=config.FS)\n",
    "\n",
    "                if len(audio_data) == 0:\n",
    "                    print(f\"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶ {file} éŸ³é¢‘æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ã€‚\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ åŠ è½½å¤±è´¥: {file}, é”™è¯¯: {e}\")\n",
    "                continue\n",
    "\n",
    "            # è®¡ç®—éŸ³é¢‘æ€»æ—¶é•¿\n",
    "            total_duration = len(audio_data) / config.FS\n",
    "\n",
    "            # è®¡ç®—å®Œæ•´çš„ 3 ç§’ç‰‡æ®µæ•°é‡\n",
    "            num_segments = math.floor(total_duration / config.SEGMENT_DURATION)\n",
    "\n",
    "            for seg_idx in range(num_segments + 1):  # +1 ä»¥è€ƒè™‘æœ€åä¸€ä¸ªä¸è¶³3ç§’çš„ç‰‡æ®µ\n",
    "                start_idx = seg_idx * config.SEGMENT_DURATION * config.FS\n",
    "                end_idx = start_idx + config.SEGMENT_DURATION * config.FS\n",
    "                segment_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "                # å¦‚æœæœ€åä¸€ä¸ªç‰‡æ®µä¸è¶³ 3sï¼Œåˆ™è¿›è¡Œ Paddingï¼ˆé›¶å¡«å……ï¼‰\n",
    "                if len(segment_audio) < config.SEGMENT_DURATION * config.FS:\n",
    "                    padding = config.SEGMENT_DURATION * config.FS - len(segment_audio)\n",
    "                    segment_audio = np.pad(segment_audio, (0, padding), mode='constant', constant_values=0)\n",
    "\n",
    "                # ç”Ÿæˆé¢‘è°±å›¾\n",
    "                spec_data = oog2spec_via_cupy(segment_audio)\n",
    "\n",
    "                if spec_data is None:\n",
    "                    print(f\"âš ï¸ é¢‘è°±æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æ–‡ä»¶ {file} çš„ç‰‡æ®µ {seg_idx}ã€‚\")\n",
    "                    continue  # è·³è¿‡è¯¥ç‰‡æ®µ\n",
    "\n",
    "                # è°ƒæ•´å°ºå¯¸\n",
    "                spec_data = cv2.resize(spec_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # ä¿å­˜é¢‘è°±æ•°æ®\n",
    "                spec_filename = f\"negative_{file.split('.')[0]}_seg{seg_idx}.npy\"\n",
    "                spec_filepath = os.path.join(config.OUTPUT_DIR, spec_filename)\n",
    "                np.save(spec_filepath, spec_data.astype(np.float32))\n",
    "\n",
    "                # è®°å½•æ•°æ®\n",
    "                negative_data.append([\"Background Noise\", \"none\", f\"negative_{file.split('.')[0]}\", seg_idx, spec_filepath])\n",
    "                negative_samples_processed += 1\n",
    "\n",
    "                # è¾¾åˆ°æœ€å¤§æ•°é‡ååœæ­¢\n",
    "                if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "                    print(f\"ğŸ¯ å·²å¤„ç† {config.MAX_NEGATIVE_SAMPLES} ä¸ªè´Ÿæ ·æœ¬ï¼Œåœæ­¢å¤„ç†ã€‚\")\n",
    "                    break\n",
    "\n",
    "            if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "                break\n",
    "\n",
    "    if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "        break\n",
    "\n",
    "# è¯»å–åŸå§‹ all_data_meta.csv\n",
    "meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta.csv\"\n",
    "if os.path.exists(meta_csv_path):\n",
    "    existing_df = pd.read_csv(meta_csv_path)\n",
    "    negative_df = pd.DataFrame(negative_data, columns=[\"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"path\"])\n",
    "    combined_df = pd.concat([existing_df, negative_df], ignore_index=True)\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°åŸå§‹ all_data_meta.csvï¼Œç”Ÿæˆæ–°çš„æ–‡ä»¶ã€‚\")\n",
    "    combined_df = pd.DataFrame(negative_data, columns=[\"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"path\"])\n",
    "\n",
    "# ç”Ÿæˆæ–°çš„ CSV æ–‡ä»¶\n",
    "new_meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_with_negative.csv\"\n",
    "combined_df.to_csv(new_meta_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nğŸ¯ è´Ÿæ ·æœ¬å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"âœ… ç”Ÿæˆäº† {negative_samples_processed} ä¸ªè´Ÿæ ·æœ¬ï¼ˆæœ€å¤§ {config.MAX_NEGATIVE_SAMPLES}ï¼‰\")\n",
    "print(f\"ğŸ“„ é¢‘è°±æ•°æ®å­˜å‚¨åœ¨ {config.OUTPUT_DIR}\")\n",
    "print(f\"ğŸ“Š æ–°çš„å…ƒæ•°æ® CSV æ–‡ä»¶å·²ä¿å­˜ï¼š{new_meta_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–°ç‰ˆç”Ÿæˆè´Ÿæ ·æœ¬specå’Œmelï¼Œå¹¶æ·»åŠ åˆ°all data meta ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Negative Audio Files:  11%|â–ˆâ–        | 874/7690 [01:04<08:20, 13.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ è¾¾åˆ°æœ€å¤§è´Ÿæ ·æœ¬æ•° 3500ï¼Œåœæ­¢å¤„ç†ã€‚\n",
      "\n",
      "âœ… è´Ÿæ ·æœ¬å¤„ç†å®Œæˆï¼Œç”Ÿæˆæ ·æœ¬æ•°ï¼š3500\n",
      "ğŸ“ çº¿æ€§è°±å­˜å‚¨è·¯å¾„: E:/AMR/DA/Projekt/data/Audio_spec_paperstyle\n",
      "ğŸ“ melè°±å­˜å‚¨è·¯å¾„: E:/AMR/DA/Projekt/data/Audio_spec_mel\n",
      "ğŸ“ æ–° CSV å·²ä¿å­˜: E:/AMR/DA/Projekt/data/all_data_meta_with_negative.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import cv2\n",
    "import math\n",
    "import cupy as cp\n",
    "from cupyx.scipy import signal as cupy_signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "# é…ç½®å‚æ•°ï¼ˆå’Œä¸»æ•°æ®ä¸€è‡´ï¼‰\n",
    "class config:\n",
    "    SEED = 2024\n",
    "    DEVICE = 'cpu'\n",
    "    OUTPUT_DIR_SPEC = \"E:/AMR/DA/Projekt/data/Audio_spec_paperstyle\"\n",
    "    OUTPUT_DIR_MEL = \"E:/AMR/DA/Projekt/data/Audio_spec_mel\"\n",
    "    FS = 48000\n",
    "    N_FFT = 512\n",
    "    WIN_SIZE = 512\n",
    "    WIN_LAP = 384\n",
    "    MIN_FREQ = 150\n",
    "    MAX_FREQ = 15000\n",
    "    SEGMENT_DURATION = 3\n",
    "    SPEC_SIZE = (512, 256)\n",
    "    MAX_NEGATIVE_SAMPLES = 3500\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(config.OUTPUT_DIR_SPEC, exist_ok=True)\n",
    "os.makedirs(config.OUTPUT_DIR_MEL, exist_ok=True)\n",
    "\n",
    "# â¤ çº¿æ€§é¢‘è°±å›¾ç”Ÿæˆ\n",
    "def oog2spec_via_cupy(audio_data):\n",
    "    if len(audio_data) == 0:\n",
    "        return None\n",
    "    audio_data = cp.array(audio_data)\n",
    "    frequencies, times, spec_data = cupy_signal.spectrogram(\n",
    "        audio_data,\n",
    "        fs=config.FS,\n",
    "        nfft=config.N_FFT,\n",
    "        nperseg=config.WIN_SIZE,\n",
    "        noverlap=config.WIN_LAP,\n",
    "        window='hann'\n",
    "    )\n",
    "    valid_freq = (frequencies >= config.MIN_FREQ) & (frequencies <= config.MAX_FREQ)\n",
    "    spec_data = spec_data[valid_freq, :]\n",
    "    spec_data = cp.log10(spec_data + 1e-20)\n",
    "    spec_data = (spec_data - spec_data.min()) / (spec_data.max() - spec_data.min() + 1e-9)\n",
    "    return spec_data.get()\n",
    "\n",
    "# â¤ mel é¢‘è°±å›¾ç”Ÿæˆ\n",
    "def audio2mel(audio_data):\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.N_FFT - config.WIN_LAP,\n",
    "        win_length=config.WIN_SIZE,\n",
    "        window='hann',\n",
    "        n_mels=64,\n",
    "        fmin=config.MIN_FREQ,\n",
    "        fmax=config.MAX_FREQ\n",
    "    )\n",
    "    mel_spec = np.log10(mel_spec + 1e-9)\n",
    "    mel_spec = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min() + 1e-9)\n",
    "    return mel_spec\n",
    "\n",
    "# â¤ å¤„ç†è´Ÿæ ·æœ¬\n",
    "negative_samples_dir = \"E:/AMR/DA/Projekt/data/negative_audio\"\n",
    "negative_samples_processed = 0\n",
    "negative_data = []\n",
    "\n",
    "for root, _, files in os.walk(negative_samples_dir):\n",
    "    for file in tqdm(files, desc=\"Processing Negative Audio Files\"):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            try:\n",
    "                audio_data, _ = librosa.load(file_path, sr=config.FS)\n",
    "                if len(audio_data) == 0:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ åŠ è½½å¤±è´¥: {file}, é”™è¯¯: {e}\")\n",
    "                continue\n",
    "\n",
    "            total_duration = len(audio_data) / config.FS\n",
    "            num_segments = math.floor(total_duration / config.SEGMENT_DURATION)\n",
    "\n",
    "            for seg_idx in range(num_segments + 1):  # åŒ…å«æœ€åç‰‡æ®µ\n",
    "                start_idx = seg_idx * config.SEGMENT_DURATION * config.FS\n",
    "                end_idx = start_idx + config.SEGMENT_DURATION * config.FS\n",
    "                segment_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "                # å¡«å……ä¸è¶³ 3 ç§’çš„ç‰‡æ®µ\n",
    "                if len(segment_audio) < config.SEGMENT_DURATION * config.FS:\n",
    "                    padding = config.SEGMENT_DURATION * config.FS - len(segment_audio)\n",
    "                    segment_audio = np.pad(segment_audio, (0, padding), mode='constant')\n",
    "\n",
    "                # â¤ ç”Ÿæˆçº¿æ€§è°±å›¾\n",
    "                spec_data = oog2spec_via_cupy(segment_audio)\n",
    "                if spec_data is None:\n",
    "                    continue\n",
    "                spec_data = cv2.resize(spec_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "                spec_filename = f\"negative_{file.split('.')[0]}_seg{seg_idx}.npy\"\n",
    "                spec_path = os.path.join(config.OUTPUT_DIR_SPEC, spec_filename)\n",
    "                np.save(spec_path, spec_data.astype(np.float32))\n",
    "\n",
    "                # â¤ ç”Ÿæˆ mel é¢‘è°±å›¾\n",
    "                mel_data = audio2mel(segment_audio)\n",
    "                mel_data = cv2.resize(mel_data, config.SPEC_SIZE, interpolation=cv2.INTER_AREA)\n",
    "                mel_filename = f\"negative_{file.split('.')[0]}_seg{seg_idx}_mel.npy\"\n",
    "                mel_path = os.path.join(config.OUTPUT_DIR_MEL, mel_filename)\n",
    "                np.save(mel_path, mel_data.astype(np.float32))\n",
    "\n",
    "                # â¤ è®°å½•è·¯å¾„ä¿¡æ¯\n",
    "                negative_data.append([\"Background Noise\", \"none\", f\"negative_{file.split('.')[0]}\", seg_idx, spec_path, mel_path])\n",
    "                negative_samples_processed += 1\n",
    "\n",
    "                if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "                    print(f\"ğŸ¯ è¾¾åˆ°æœ€å¤§è´Ÿæ ·æœ¬æ•° {config.MAX_NEGATIVE_SAMPLES}ï¼Œåœæ­¢å¤„ç†ã€‚\")\n",
    "                    break\n",
    "\n",
    "            if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "                break\n",
    "    if negative_samples_processed >= config.MAX_NEGATIVE_SAMPLES:\n",
    "        break\n",
    "\n",
    "# â¤ åˆå¹¶ CSV\n",
    "meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta.csv\"\n",
    "new_meta_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_with_negative.csv\"\n",
    "\n",
    "if os.path.exists(meta_csv_path):\n",
    "    existing_df = pd.read_csv(meta_csv_path)\n",
    "    negative_df = pd.DataFrame(negative_data, columns=[\"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"spec_path\", \"mel_path\"])\n",
    "    combined_df = pd.concat([existing_df, negative_df], ignore_index=True)\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°åŸå§‹ CSVï¼Œä»…ä½¿ç”¨è´Ÿæ ·æœ¬ç”Ÿæˆæ–°æ–‡ä»¶ã€‚\")\n",
    "    combined_df = pd.DataFrame(negative_data, columns=[\"bird_name\", \"vocalization\", \"number\", \"segment_index\", \"spec_path\", \"mel_path\"])\n",
    "\n",
    "# â¤ ä¿å­˜æ–° CSV\n",
    "combined_df.to_csv(new_meta_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nâœ… è´Ÿæ ·æœ¬å¤„ç†å®Œæˆï¼Œç”Ÿæˆæ ·æœ¬æ•°ï¼š{negative_samples_processed}\")\n",
    "print(f\"ğŸ“ çº¿æ€§è°±å­˜å‚¨è·¯å¾„: {config.OUTPUT_DIR_SPEC}\")\n",
    "print(f\"ğŸ“ melè°±å­˜å‚¨è·¯å¾„: {config.OUTPUT_DIR_MEL}\")\n",
    "print(f\"ğŸ“ æ–° CSV å·²ä¿å­˜: {new_meta_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectogram.npy Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” å¼€å§‹æ£€æŸ¥ .npy æ–‡ä»¶...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\40920\\.conda\\envs\\testenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_csv_path)\n\u001b[0;32m     52\u001b[0m blacklist \u001b[38;5;241m=\u001b[39m load_blacklist()\n\u001b[1;32m---> 53\u001b[0m invalid_files \u001b[38;5;241m=\u001b[39m \u001b[43mfind_invalid_npy_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblacklist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m save_blacklist(invalid_files)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# è¿‡æ»¤æ— æ•ˆæ•°æ®\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mfind_invalid_npy_files\u001b[1;34m(df, blacklist)\u001b[0m\n\u001b[0;32m     27\u001b[0m invalid_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(blacklist)  \u001b[38;5;66;03m# å…ˆåŠ è½½å·²æœ‰çš„é»‘åå•\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ” å¼€å§‹æ£€æŸ¥ .npy æ–‡ä»¶...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ‰«ææ— æ•ˆæ•°æ®\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m invalid_files:\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# è·³è¿‡å·²çŸ¥æ— æ•ˆæ–‡ä»¶\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\40920\\.conda\\envs\\testenv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\40920\\.conda\\envs\\testenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'path'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ“Œ æ–‡ä»¶è·¯å¾„\n",
    "data_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_with_negative.csv\"  # åŸå§‹æ•°æ®\n",
    "clean_data_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_clean.csv\"  # è¿‡æ»¤åæ•°æ®\n",
    "blacklist_path = \"E:/AMR/DA/Projekt/data/blacklist.txt\"  # é»‘åå•æ–‡ä»¶\n",
    "\n",
    "# è¯»å–é»‘åå•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "def load_blacklist():\n",
    "    if os.path.exists(blacklist_path):\n",
    "        with open(blacklist_path, \"r\") as f:\n",
    "            return set(line.strip() for line in f.readlines())\n",
    "    return set()\n",
    "\n",
    "# ä¿å­˜é»‘åå•\n",
    "def save_blacklist(blacklist):\n",
    "    with open(blacklist_path, \"w\") as f:\n",
    "        for file in blacklist:\n",
    "            f.write(file + \"\\n\")\n",
    "    print(f\"âœ… é»‘åå•å·²æ›´æ–°ï¼Œå…± {len(blacklist)} ä¸ªæ— æ•ˆæ–‡ä»¶\")\n",
    "\n",
    "# æ£€æŸ¥ `.npy` æ–‡ä»¶æ˜¯å¦åŒ…å« NaN/Inf\n",
    "def find_invalid_npy_files(df, blacklist):\n",
    "    invalid_files = set(blacklist)  # å…ˆåŠ è½½å·²æœ‰çš„é»‘åå•\n",
    "\n",
    "    print(\"ğŸ” å¼€å§‹æ£€æŸ¥ .npy æ–‡ä»¶...\")\n",
    "    for file_path in tqdm(df[\"path\"], desc=\"æ‰«ææ— æ•ˆæ•°æ®\"):\n",
    "        if file_path in invalid_files:\n",
    "            continue  # è·³è¿‡å·²çŸ¥æ— æ•ˆæ–‡ä»¶\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "            invalid_files.add(file_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            spectrogram = np.load(file_path)\n",
    "            if np.isnan(spectrogram).any() or np.isinf(spectrogram).any():\n",
    "                print(f\"âŒ å‘ç° NaN/Inf: {file_path}\")\n",
    "                invalid_files.add(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è¯»å–å¤±è´¥: {file_path}, é”™è¯¯: {e}\")\n",
    "            invalid_files.add(file_path)\n",
    "\n",
    "    return invalid_files\n",
    "\n",
    "# è¿è¡Œæ•°æ®è¿‡æ»¤\n",
    "df = pd.read_csv(data_csv_path)\n",
    "blacklist = load_blacklist()\n",
    "invalid_files = find_invalid_npy_files(df, blacklist)\n",
    "save_blacklist(invalid_files)\n",
    "\n",
    "# è¿‡æ»¤æ— æ•ˆæ•°æ®\n",
    "df_clean = df[~df[\"path\"].isin(invalid_files)]\n",
    "df_clean.to_csv(clean_data_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… å·²è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼Œç”Ÿæˆ {clean_data_csv_path}ï¼ˆä¿ç•™ {len(df_clean)} æ¡æ•°æ®ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¿®æ”¹æ ‡ç­¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm  # è¿›åº¦æ¡ï¼Œæ–¹ä¾¿è§‚å¯Ÿè¿›åº¦\n",
    "\n",
    "# å®šä¹‰ hasBird() æ–¹æ³•\n",
    "def hasBird(spec, threshold=16):\n",
    "    img = spec.copy()\n",
    "    \n",
    "    # STEP 1: Median blur\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    \n",
    "    # STEP 2: Median threshold\n",
    "    col_median = np.median(img, axis=0, keepdims=True)\n",
    "    row_median = np.median(img, axis=1, keepdims=True)\n",
    "    img[img < row_median * 1.2] = 0\n",
    "    img[img < col_median * 1.2] = 0\n",
    "    img[img > 0] = 1\n",
    "    \n",
    "    # STEP 3: Remove isolated pixels\n",
    "    struct = np.ones((3, 3))\n",
    "    id_regions, num_ids = ndimage.label(img, structure=struct)\n",
    "    id_sizes = np.array(ndimage.sum(img, id_regions, range(num_ids + 1)))\n",
    "    area_mask = (id_sizes == 1)\n",
    "    img[area_mask[id_regions]] = 0\n",
    "    \n",
    "    # STEP 4: Morphological closing\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.float32))\n",
    "    \n",
    "    # STEP 5: Frequency crop (keeping middle frequency range)\n",
    "    img = img[8:-85, :]\n",
    "    \n",
    "    # STEP 6: Count active rows\n",
    "    row_max = np.max(img, axis=1)\n",
    "    row_max = ndimage.binary_dilation(row_max, iterations=2).astype(row_max.dtype)\n",
    "    rthresh = row_max.sum()\n",
    "    \n",
    "    # STEP 7: Apply threshold\n",
    "    return rthresh >= threshold\n",
    "\n",
    "# è¯»å– CSV æ–‡ä»¶\n",
    "csv_path = \"E:/AMR/DA/Projekt/data/valid_list_for_zoom006_100_nofreefiled.csv\"\n",
    "output_csv_path = \"E:/AMR/DA/Projekt/data/vliad_list_for_zoom006_100_nofreefiled_refine_th12.csv\"\n",
    "counter = 0\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# éå† CSVï¼Œå¤„ç†æ¯ä¸ªé¢‘è°±å›¾\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # å¦‚æœ bird_name å·²ç»æ˜¯ \"Background Noise\"ï¼Œè·³è¿‡æ£€æµ‹\n",
    "    if row[\"bird_name\"] == \"Background Noise\":\n",
    "        continue  \n",
    "\n",
    "    spec_path = row[\"path\"].replace(\"\\\\\", \"/\")  # å…¼å®¹ Windows è·¯å¾„\n",
    "    try:\n",
    "        # è¯»å– .npy é¢‘è°±æ•°æ®\n",
    "        spec_data = np.load(spec_path)\n",
    "        \n",
    "        # åˆ¤æ–­æ˜¯å¦æœ‰é¸Ÿå£°\n",
    "        if not hasBird(spec_data):\n",
    "            df.at[idx, \"bird_name\"] = \"Background Noise\"\n",
    "            df.at[idx, \"vocalization\"] = \"none\"\n",
    "            counter += 1\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ— æ³•å¤„ç†æ–‡ä»¶: {spec_path}, é”™è¯¯: {e}\")\n",
    "\n",
    "# ä¿å­˜æ–°çš„ CSV æ–‡ä»¶\n",
    "df.to_csv(output_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… å¤„ç†å®Œæˆï¼Œå·²ä¿å­˜è‡³ {output_csv_path}\")\n",
    "print(f\"éœ€è¦ä¿®æ”¹çš„æ•°é‡ï¼š{counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# å¯è§†åŒ–ä¸­é—´æ­¥éª¤\n",
    "def visualize_step(title, img):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(img, aspect='auto', cmap='magma', origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# é€‰æ‹©ä¸€ä¸ª `.npy` æ ·æœ¬è·¯å¾„ï¼ˆä½ å¯ä»¥æ‰‹åŠ¨æ”¹æˆä½ æƒ³æµ‹è¯•çš„æ–‡ä»¶ï¼‰\n",
    "spec_path = \"E:/AMR/DA/Projekt/data/Audio_spec\\XC864575_seg28.npy\"\n",
    "\n",
    "spec_data = np.load(spec_path)\n",
    "\n",
    "def hasBird_debug(spec, threshold=16):\n",
    "    img = spec.copy()\n",
    "\n",
    "    # STEP 1: åŸå§‹é¢‘è°±å›¾\n",
    "    visualize_step(\"Step 1: raw spec\", img)\n",
    "    \n",
    "    # STEP 2: Median blur\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    visualize_step(\"Step 2: after Median Blur\", img)\n",
    "\n",
    "    # STEP 3: Median threshold\n",
    "    col_median = np.median(img, axis=0, keepdims=True)\n",
    "    row_median = np.median(img, axis=1, keepdims=True)\n",
    "    img[img < row_median * 1.2] = 0\n",
    "    img[img < col_median * 1.2] = 0   # baseline = 1.2\n",
    "    img[img > 0] = 1\n",
    "    visualize_step(\"Step 3: after Median threshold\", img)\n",
    "\n",
    "    # STEP 4: Remove isolated pixels\n",
    "    struct = np.ones((3, 3))\n",
    "    id_regions, num_ids = ndimage.label(img, structure=struct)\n",
    "    id_sizes = np.array(ndimage.sum(img, id_regions, range(num_ids + 1)))\n",
    "    area_mask = (id_sizes == 1)\n",
    "    img[area_mask[id_regions]] = 0\n",
    "    visualize_step(\"Step 4: after Remove isolated pixels\", img)\n",
    "\n",
    "    # STEP 5: Morphological closing\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.float32))\n",
    "    visualize_step(\"Step 5: after Morphological closing\", img)\n",
    "\n",
    "    # STEP 6: Frequency crop (keeping middle frequency range)\n",
    "    img = img[8:-85, :]\n",
    "    visualize_step(\"Step 6: after Frequency crop \", img)\n",
    "\n",
    "    # STEP 7: Count active rows\n",
    "    row_max = np.max(img, axis=1)\n",
    "    row_max = ndimage.binary_dilation(row_max, iterations=2).astype(row_max.dtype)\n",
    "    rthresh = row_max.sum()\n",
    "\n",
    "    print(f\"Step 7: Count active rows: {rthresh}\")\n",
    "\n",
    "    # STEP 8: Apply threshold\n",
    "    result = rthresh >= threshold\n",
    "    print(f\"Step 8: has bird? {result}\")\n",
    "    return result\n",
    "\n",
    "# è¿è¡Œè°ƒè¯•ç‰ˆ hasBird æ–¹æ³•\n",
    "hasBird_debug(spec_data, threshold=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------\n",
    "# åœ¨æ­¤ä¹‹å‰çš„ä»£ç ä¸€èˆ¬åªç”¨æ‰§è¡Œä¸€æ¬¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Target filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ“Œ æ–‡ä»¶è·¯å¾„\n",
    "input_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_clean.csv\"  # ç»è¿‡ NaN/Inf è¿‡æ»¤å’Œæ ‡ç­¾ä¿®æ­£çš„æ–‡ä»¶\n",
    "# input_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta.csv\"  # ç»è¿‡ NaN/Inf è¿‡æ»¤å’Œæ ‡ç­¾ä¿®æ­£çš„æ–‡ä»¶\n",
    "output_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_allTypes.csv\"  # ç›®æ ‡é¸Ÿç±»æ•°æ®\n",
    "\n",
    "# ğŸ¯ ç›®æ ‡é¸Ÿç±»ï¼ˆä»…ä¿ç•™è¿™äº›ç±»åˆ«ï¼‰\n",
    "# selected_birds = [\n",
    "#     \"Eurasian Blue tit\",\n",
    "#     \"Eurasian Bullfinch\",\n",
    "#     \"Great Tit\",\n",
    "#     \"Hawfinch\",\n",
    "#     \"Hooded Crow\",\n",
    "#     \"Stock Dove\",\n",
    "#     \"Background Noise\",\n",
    "# ]\n",
    "\n",
    "selected_birds = [\n",
    "    \"Black-headed Gull\",\n",
    "    \"Canada Goose\",\n",
    "    \"Carrion Crow\",\n",
    "    \"Common Blackbird\",\n",
    "    \"Common Chaffinch\",\n",
    "    \"Common Kingfisher\",\n",
    "    \"Common Redstart\",\n",
    "    \"Common Wood Pigeon\",\n",
    "    \"Dunnock\",\n",
    "    \"Eurasian Blackcap\",\n",
    "    \"Eurasian Blue tit\",\n",
    "    \"Eurasian Bullfinch\",\n",
    "    \"Eurasian Coot\",\n",
    "    \"Eurasian Golden Oriole\",\n",
    "    \"Eurasian Jay\",\n",
    "    \"Eurasian Nuthatch\",\n",
    "    \"Eurasian Siskin\",\n",
    "    \"Eurasian Treecreeper\",\n",
    "    \"Eurasian Wren\",\n",
    "    \"European Goldfinch\",\n",
    "    \"European Robin\",\n",
    "    \"Goldcrest\",\n",
    "    \"Great Spotted Woodpecker\",\n",
    "    \"Great Tit\",\n",
    "    \"Hawfinch\",\n",
    "    \"Hooded Crow\",\n",
    "    \"Long-tailed Tit\",\n",
    "    \"Mallard\",\n",
    "    \"Marsh Tit\",\n",
    "    \"Redwing\",\n",
    "    \"Rook\",\n",
    "    \"Short-toed Treecreeper\",\n",
    "    \"Stock Dove\",\n",
    "    \"Background Noise\",\n",
    "    \"Background Noise\",\n",
    "]\n",
    "\n",
    "# ğŸ¯ vocalization è¿‡æ»¤æ¡ä»¶ï¼ˆæ ¹æ®ä½ çš„å®é™…éœ€æ±‚ä¿®æ”¹ï¼‰\n",
    "selected_vocalization = [\"Call\", \"Song\", \"Alarm call\", \"Flight call\", \"Begging call\", \"none\"]  # å‡è®¾ä½ åªæƒ³ä¿ç•™ vocalization ä¸º 'call' æˆ– 'song' çš„æ ·æœ¬\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "df = pd.read_csv(input_csv_path)\n",
    "print(f\"ğŸ“Š è¿‡æ»¤å‰æ•°æ®: {len(df)} æ¡\")\n",
    "\n",
    "# åªä¿ç•™ç›®æ ‡é¸Ÿç±»\n",
    "df_filtered = df[df[\"bird_name\"].isin(selected_birds)]\n",
    "\n",
    "# åªä¿ç•™ç¬¦åˆ vocalization æ¡ä»¶çš„æ•°æ®\n",
    "df_filtered = df_filtered[df_filtered[\"vocalization\"].isin(selected_vocalization)]\n",
    "\n",
    "# ä¿å­˜ç­›é€‰åçš„æ•°æ®\n",
    "df_filtered.to_csv(output_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… ç›®æ ‡é¸Ÿç±»å’Œ vocalization ç­›é€‰å®Œæˆï¼Œç”Ÿæˆ {output_csv_path}ï¼ˆä¿ç•™ {len(df_filtered)} æ¡æ•°æ®ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ“Œ ä½ çš„ CSV æ–‡ä»¶è·¯å¾„\n",
    "data_csv_path = \"E:/AMR/DA/Projekt/data/train_list_for_zoom006_0324.csv\"\n",
    "\n",
    "# âœ… **æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨**\n",
    "if not os.path.exists(data_csv_path):\n",
    "    print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {data_csv_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# è¯»å– CSV æ•°æ®\n",
    "df = pd.read_csv(data_csv_path)\n",
    "\n",
    "# ç»Ÿè®¡æ¯ä¸ªç±»åˆ«ï¼ˆbird_nameï¼‰çš„æ ·æœ¬æ•°é‡\n",
    "class_counts = df[\"bird_name\"].value_counts().reset_index()\n",
    "class_counts.columns = [\"ç±»åˆ«\", \"æ ·æœ¬æ•°é‡\"]\n",
    "\n",
    "# ğŸ“Œ **æ‰“å°ç»“æœ**\n",
    "print(\"ğŸ“Š å„ç±»åˆ«æ ·æœ¬æ•°é‡ç»Ÿè®¡ï¼š\")\n",
    "print(class_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ğŸ“Œ æ–‡ä»¶è·¯å¾„\n",
    "data_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_allTypes.csv\"\n",
    "train_csv_path = \"E:/AMR/DA/Projekt/data/train_list_for_zoom006_0324.csv\"\n",
    "test_csv_path = \"E:/AMR/DA/Projekt/data/valid_list_for_zoom006_0324.csv\"\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "df = pd.read_csv(data_csv_path)\n",
    "print(f\"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡\")\n",
    "\n",
    "# âœ… **å®šä¹‰éŸ³é¢‘ç¼–å·è§£æå‡½æ•°**\n",
    "def get_audio_id(number, bird_name):\n",
    "    if bird_name == \"Background Noise\":\n",
    "        return number\n",
    "    return number.split(\"_\")[0] if \"_\" in number else number\n",
    "\n",
    "# è®¡ç®— `audio_id`\n",
    "df[\"audio_id\"] = df.apply(lambda row: get_audio_id(row[\"number\"], row[\"bird_name\"]), axis=1)\n",
    "\n",
    "# ğŸš€ æ‹†åˆ†ä¸ºæ™®é€šæ ·æœ¬å’Œè´Ÿæ ·æœ¬\n",
    "neg_samples = df[df[\"bird_name\"] == \"Background Noise\"].copy()\n",
    "pos_samples = df[df[\"bird_name\"] != \"Background Noise\"].copy()\n",
    "\n",
    "# âœ… æŒ‰ audio_id è¿›è¡Œè®­ç»ƒ/æµ‹è¯•åˆ’åˆ†ï¼ˆ20% æµ‹è¯•é›†ï¼‰\n",
    "unique_audio_ids = pos_samples[\"audio_id\"].unique()\n",
    "train_audio_ids, test_audio_ids = train_test_split(unique_audio_ids, test_size=0.2, random_state=2024, shuffle=True)\n",
    "\n",
    "train_df = pos_samples[pos_samples[\"audio_id\"].isin(train_audio_ids)]\n",
    "test_df = pos_samples[pos_samples[\"audio_id\"].isin(test_audio_ids)]\n",
    "\n",
    "# âœ… é™åˆ¶æµ‹è¯•é›†æ¯ç±»ä¸è¶…è¿‡ 500 ä¸ªæ ·æœ¬ï¼Œå‰©ä¸‹çš„å›æµåˆ°è®­ç»ƒé›†ï¼ˆæ’é™¤ç¢ç‰‡æ³„éœ²ï¼‰\n",
    "test_limited_df = []\n",
    "train_remainder_df = []\n",
    "test_audio_ids_set = set(test_df[\"audio_id\"])\n",
    "\n",
    "for bird_name in test_df[\"bird_name\"].unique():\n",
    "    class_samples = test_df[test_df[\"bird_name\"] == bird_name]\n",
    "\n",
    "    if len(class_samples) > 500:\n",
    "        test_limited = class_samples.sample(n=500, random_state=2024)\n",
    "        remainder = class_samples.drop(test_limited.index)\n",
    "\n",
    "        # â— ç§»é™¤ä¸ test_limited ç›¸åŒ audio_id çš„ç¢ç‰‡ï¼Œé¿å…å›æµæ±¡æŸ“\n",
    "        remainder = remainder[~remainder[\"audio_id\"].isin(test_limited[\"audio_id\"])]\n",
    "        train_remainder = remainder\n",
    "    else:\n",
    "        test_limited = class_samples\n",
    "        train_remainder = pd.DataFrame()\n",
    "\n",
    "    test_limited_df.append(test_limited)\n",
    "    train_remainder_df.append(train_remainder)\n",
    "\n",
    "# åˆå¹¶æµ‹è¯•é›† & å®‰å…¨å›æµè®­ç»ƒé›†\n",
    "test_df = pd.concat(test_limited_df, ignore_index=True)\n",
    "train_df = pd.concat([train_df] + train_remainder_df, ignore_index=True)\n",
    "\n",
    "# âœ… èƒŒæ™¯å™ªå£°åˆ’åˆ†\n",
    "neg_audio_ids = neg_samples[\"audio_id\"].unique()\n",
    "print(\"\\nğŸ” è´Ÿæ ·æœ¬ `audio_id` ç»Ÿè®¡ï¼š\")\n",
    "print(pd.Series(neg_audio_ids).value_counts())\n",
    "\n",
    "if len(neg_audio_ids) >= 2:\n",
    "    train_neg_ids, test_neg_ids = train_test_split(neg_audio_ids, test_size=0.2, random_state=2024, shuffle=True)\n",
    "    train_neg_df = neg_samples[neg_samples[\"audio_id\"].isin(train_neg_ids)]\n",
    "    test_neg_df = neg_samples[neg_samples[\"audio_id\"].isin(test_neg_ids)]\n",
    "else:\n",
    "    print(f\"âš ï¸ è´Ÿæ ·æœ¬æ•°é‡ä¸è¶³ ({len(neg_audio_ids)} ä¸ª)ï¼Œå…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†ï¼\")\n",
    "    train_neg_df = neg_samples\n",
    "    test_neg_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# âœ… åˆå¹¶è®­ç»ƒ & æµ‹è¯•é›†\n",
    "train_df = pd.concat([train_df, train_neg_df], ignore_index=True)\n",
    "test_df = pd.concat([test_df, test_neg_df], ignore_index=True)\n",
    "\n",
    "# âœ… åˆ é™¤è¾…åŠ©åˆ— audio_id\n",
    "train_df.drop(columns=[\"audio_id\"], inplace=True)\n",
    "test_df.drop(columns=[\"audio_id\"], inplace=True)\n",
    "\n",
    "# âœ… ä¿å­˜ CSV æ–‡ä»¶\n",
    "os.makedirs(os.path.dirname(train_csv_path), exist_ok=True)\n",
    "train_df.to_csv(train_csv_path, index=False, encoding=\"utf-8\")\n",
    "test_df.to_csv(test_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… è®­ç»ƒé›†å·²ä¿å­˜è‡³: {train_csv_path}, æ ·æœ¬æ•°: {len(train_df)}\")\n",
    "print(f\"âœ… æµ‹è¯•é›†å·²ä¿å­˜è‡³: {test_csv_path}, æ ·æœ¬æ•°: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ğŸ“Œ é…ç½®\n",
    "data_csv_path = \"E:/AMR/DA/Projekt/data/all_data_meta_filtered.csv\"  # ç›®æ ‡é¸Ÿç±»æ•°æ®\n",
    "output_dir = \"E:/AMR/DA/Projekt/data\"  # äº¤å‰éªŒè¯æ•°æ®ä¿å­˜ç›®å½•\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "df = pd.read_csv(data_csv_path)\n",
    "print(f\"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡\")\n",
    "\n",
    "# æå–éŸ³é¢‘ç¼–å·ï¼ˆå»æ‰ segXï¼‰\n",
    "df[\"audio_id\"] = df[\"number\"].apply(lambda x: x.split(\"_\")[0] if \"_\" in x else x)\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ğŸš€ **æŒ‰éŸ³é¢‘ç¼–å·è¿›è¡Œåˆ’åˆ†ï¼ˆç¡®ä¿æ‰€æœ‰ç‰‡æ®µåœ¨åŒä¸€ä¸ªé›†åˆï¼‰**\n",
    "unique_audio_ids = df[\"audio_id\"].unique()\n",
    "part1_audio_ids, part2_audio_ids = train_test_split(unique_audio_ids, test_size=0.5, random_state=2024, shuffle=True)\n",
    "\n",
    "# **åˆ†é…æ•°æ®**\n",
    "part1_df = df[df[\"audio_id\"].isin(part1_audio_ids)].drop(columns=[\"audio_id\"])\n",
    "part2_df = df[df[\"audio_id\"].isin(part2_audio_ids)].drop(columns=[\"audio_id\"])\n",
    "\n",
    "# **ä¿å­˜æ–‡ä»¶**\n",
    "part1_csv_path = os.path.join(output_dir, \"crossval_part1.csv\")\n",
    "part2_csv_path = os.path.join(output_dir, \"crossval_part2.csv\")\n",
    "\n",
    "part1_df.to_csv(part1_csv_path, index=False, encoding=\"utf-8\")\n",
    "part2_df.to_csv(part2_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… äº¤å‰éªŒè¯æ•°æ®é›† 1: {part1_csv_path}, æ ·æœ¬æ•°: {len(part1_df)}\")\n",
    "print(f\"âœ… äº¤å‰éªŒè¯æ•°æ®é›† 2: {part2_csv_path}, æ ·æœ¬æ•°: {len(part2_df)}\")\n",
    "print(\"\\nğŸ¯ äº¤å‰éªŒè¯æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and valid distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"E:/AMR/DA/Projekt/data/train_list_for_zoom006_0315.csv\")\n",
    "valid_df = pd.read_csv(\"E:/AMR/DA/Projekt/data/valid_list_for_zoom006_0315.csv\")\n",
    "\n",
    "print(\"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "print(train_df[\"bird_name\"].value_counts())\n",
    "\n",
    "print(\"\\næµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "print(valid_df[\"bird_name\"].value_counts())\n",
    "\n",
    "train_df_refine = pd.read_csv(\"E:/AMR/DA/Projekt/data/train_list_for_zoom006_100_nofreefiled_refine_th12.csv\")\n",
    "valid_df_refine = pd.read_csv(\"E:/AMR/DA/Projekt/data/valid_list_for_zoom006_100_nofreefiled_refine_th12.csv\")\n",
    "\n",
    "print(\"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒrefine:\")\n",
    "print(train_df_refine[\"bird_name\"].value_counts())\n",
    "print(\"\\næµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒrefine:\")\n",
    "print(valid_df_refine[\"bird_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "# ğŸ“Œ ä½ çš„éŸ³é¢‘æ•°æ®å­˜æ”¾çš„æ ¹ç›®å½•ï¼ˆä¿®æ”¹ä¸ºä½ çš„è·¯å¾„ï¼‰\n",
    "audio_root = \"E:/AMR/DA/Projekt/data/Audio_files\"\n",
    "\n",
    "# ğŸ“Œ ç»Ÿè®¡éŸ³é¢‘ç¼–å·å‡ºç°çš„æ–‡ä»¶å¤¹\n",
    "xc_file_map = collections.defaultdict(set)\n",
    "\n",
    "# ğŸš€ éå†æ‰€æœ‰ vocalization æ–‡ä»¶å¤¹\n",
    "for vocalization in os.listdir(audio_root):\n",
    "    vocalization_path = os.path.join(audio_root, vocalization)\n",
    "    \n",
    "    if os.path.isdir(vocalization_path):  # ç¡®ä¿æ˜¯æ–‡ä»¶å¤¹\n",
    "        for file in os.listdir(vocalization_path):\n",
    "            if file.endswith(\".wav\") and file.startswith(\"XC\"):\n",
    "                xc_id = file.split(\".\")[0]  # è·å–éŸ³é¢‘ç¼–å·ï¼Œä¾‹å¦‚ XC123456\n",
    "                xc_file_map[xc_id].add(vocalization)  # è®°å½•è¯¥éŸ³é¢‘åœ¨å“ªäº› vocalization ä¸­å‡ºç°\n",
    "\n",
    "# ğŸš€ æ‰¾åˆ°é‡å¤å‡ºç°çš„éŸ³é¢‘\n",
    "duplicates = {xc: v for xc, v in xc_file_map.items() if len(v) > 1}\n",
    "\n",
    "# ğŸ“Œ æŒ‰ç…§å‡ºç°çš„ vocalization æ•°é‡æ’åº\n",
    "sorted_duplicates = sorted(duplicates.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "# âœ… æ‰“å°ç»“æœ\n",
    "print(f\"ğŸ” å…±æœ‰ {len(sorted_duplicates)} ä¸ªéŸ³é¢‘æ–‡ä»¶å‡ºç°åœ¨å¤šä¸ª vocalization ç›®å½•ä¸­:\\n\")\n",
    "for xc_id, voc_types in sorted_duplicates:\n",
    "    print(f\"{xc_id}: å‡ºç°åœ¨ {len(voc_types)} ä¸ª vocalization ä¸­ â†’ {', '.join(voc_types)}\")\n",
    "\n",
    "# ğŸ“Œ ä¿å­˜ç»“æœåˆ° CSV\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([(xc_id, len(voc_types), \", \".join(voc_types)) for xc_id, voc_types in sorted_duplicates],\n",
    "                  columns=[\"XC_ID\", \"Vocalization Count\", \"Vocalization Types\"])\n",
    "df.to_csv(\"E:/AMR/DA/Projekt/data/duplicate_audio_files.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nâœ… ç»Ÿè®¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ `duplicate_audio_files.csv`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ“Œ ä½ çš„ CSV æ–‡ä»¶è·¯å¾„\n",
    "csv_path = \"E:/AMR/DA/Projekt/data/train_meta_100.csv\"\n",
    "output_csv_path = \"E:/AMR/DA/Projekt/data/train_meta_100_deduplicated.csv\"\n",
    "\n",
    "# âœ… è¯»å– CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# âœ… æå– `XC` ç¼–å·\n",
    "df[\"XC_ID\"] = df[\"number\"].apply(lambda x: x.split(\"_\")[0] if \"_\" in x else x)\n",
    "\n",
    "# âœ… **å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„ XC_IDï¼‰**\n",
    "df_deduplicated = df.drop_duplicates(subset=\"XC_ID\", keep=\"first\")\n",
    "\n",
    "# âœ… **åˆ é™¤ `XC_ID` è¾…åŠ©åˆ—**\n",
    "df_deduplicated = df_deduplicated.drop(columns=[\"XC_ID\"])\n",
    "\n",
    "# âœ… ä¿å­˜å»é‡åçš„ CSV\n",
    "df_deduplicated.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… å»é‡å®Œæˆï¼åŸå§‹æ•°æ®: {len(df)} æ¡ â†’ å¤„ç†å: {len(df_deduplicated)} æ¡\")\n",
    "print(f\"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {output_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
